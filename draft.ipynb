{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "codelab link: https://colab.research.google.com/github/abzzall/unsupervised_annotator1/blob/main/main.ipynb\n",
    "github link: https://github.com/abzzall/unsupervised_annotator1.git"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8324742abac66bee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Install dependencies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "670531ff36b9c804"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "['Collecting spacy',\n '  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/d6/9e/8afc618cfed4b5dc602b11754d4d9193a268439704defae301bffca7f04c/spacy-3.6.1-cp311-cp311-win_amd64.whl.metadata',\n '  Downloading spacy-3.6.1-cp311-cp311-win_amd64.whl.metadata (26 kB)',\n 'Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)',\n '  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)',\n 'Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)',\n '  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)',\n 'Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)',\n '  Downloading murmurhash-1.0.9-cp311-cp311-win_amd64.whl (18 kB)',\n 'Collecting cymem<2.1.0,>=2.0.2 (from spacy)',\n '  Downloading cymem-2.0.7-cp311-cp311-win_amd64.whl (28 kB)',\n 'Collecting preshed<3.1.0,>=3.0.2 (from spacy)',\n '  Downloading preshed-3.0.8-cp311-cp311-win_amd64.whl (91 kB)',\n '     ---------------------------------------- 0.0/91.9 kB ? eta -:--:--',\n '     ---------------- --------------------- 41.0/91.9 kB 991.0 kB/s eta 0:00:01',\n '     ---------------- --------------------- 41.0/91.9 kB 991.0 kB/s eta 0:00:01',\n '     -------------------------------------- 91.9/91.9 kB 749.3 kB/s eta 0:00:00',\n 'Collecting thinc<8.2.0,>=8.1.8 (from spacy)',\n '  Obtaining dependency information for thinc<8.2.0,>=8.1.8 from https://files.pythonhosted.org/packages/ea/65/9fe6fe1ddb5fd34b7b81dada121e6862791e624384a2964331d0228aea38/thinc-8.1.12-cp311-cp311-win_amd64.whl.metadata',\n '  Downloading thinc-8.1.12-cp311-cp311-win_amd64.whl.metadata (15 kB)',\n 'Collecting wasabi<1.2.0,>=0.9.1 (from spacy)',\n '  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/8f/69/26cbf0bad11703241cb84d5324d868097f7a8faf2f1888354dac8883f3fc/wasabi-1.1.2-py3-none-any.whl.metadata',\n '  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)',\n 'Collecting srsly<3.0.0,>=2.4.3 (from spacy)',\n '  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/c6/05/d8cf64f4595080ef4b011359a98be212c29450c804cd3bde637ba007a0d6/srsly-2.4.7-cp311-cp311-win_amd64.whl.metadata',\n '  Downloading srsly-2.4.7-cp311-cp311-win_amd64.whl.metadata (20 kB)',\n 'Collecting catalogue<2.1.0,>=2.0.6 (from spacy)',\n '  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/45/8f/5b73efc14e0373d9bb0de6ce1ab04a8f77420dc473f1f3ef270caf085cff/catalogue-2.0.9-py3-none-any.whl.metadata',\n '  Downloading catalogue-2.0.9-py3-none-any.whl.metadata (14 kB)',\n 'Collecting typer<0.10.0,>=0.3.0 (from spacy)',\n '  Downloading typer-0.9.0-py3-none-any.whl (45 kB)',\n '     ---------------------------------------- 0.0/45.9 kB ? eta -:--:--',\n '     ---------------------------------------- 45.9/45.9 kB 2.2 MB/s eta 0:00:00',\n 'Collecting pathy>=0.10.0 (from spacy)',\n '  Obtaining dependency information for pathy>=0.10.0 from https://files.pythonhosted.org/packages/b5/c3/04a002ace658133f5ac48d30258ed9ceab720595dc1ac36df02fe52018af/pathy-0.10.2-py3-none-any.whl.metadata',\n '  Downloading pathy-0.10.2-py3-none-any.whl.metadata (16 kB)',\n 'Collecting smart-open<7.0.0,>=5.2.1 (from spacy)',\n '  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)',\n '     ---------------------------------------- 0.0/56.8 kB ? eta -:--:--',\n '     ---------------------------------------- 56.8/56.8 kB 3.1 MB/s eta 0:00:00',\n 'Collecting tqdm<5.0.0,>=4.38.0 (from spacy)',\n '  Obtaining dependency information for tqdm<5.0.0,>=4.38.0 from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata',\n '  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)',\n 'Collecting numpy>=1.15.0 (from spacy)',\n '  Obtaining dependency information for numpy>=1.15.0 from https://files.pythonhosted.org/packages/72/b2/02770e60c4e2f7e158d923ab0dea4e9f146a2dbf267fec6d8dc61d475689/numpy-1.25.2-cp311-cp311-win_amd64.whl.metadata',\n '  Using cached numpy-1.25.2-cp311-cp311-win_amd64.whl.metadata (5.7 kB)',\n 'Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (2.31.0)',\n 'Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)',\n '  Obtaining dependency information for pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 from https://files.pythonhosted.org/packages/82/06/fafdc75e48b248eff364b4249af4bcc6952225e8f20e8205820afc66e88e/pydantic-2.3.0-py3-none-any.whl.metadata',\n '  Downloading pydantic-2.3.0-py3-none-any.whl.metadata (148 kB)',\n '     ---------------------------------------- 0.0/148.8 kB ? eta -:--:--',\n '     ---------------------------- --------- 112.6/148.8 kB 3.3 MB/s eta 0:00:01',\n '     ------------------------------- ------ 122.9/148.8 kB 1.4 MB/s eta 0:00:01',\n '     -------------------------------------- 148.8/148.8 kB 1.5 MB/s eta 0:00:00',\n 'Requirement already satisfied: jinja2 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (3.1.2)',\n 'Requirement already satisfied: setuptools in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (68.0.0)',\n 'Requirement already satisfied: packaging>=20.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (23.1)',\n 'Collecting langcodes<4.0.0,>=3.2.0 (from spacy)',\n '  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)',\n '     ---------------------------------------- 0.0/181.6 kB ? eta -:--:--',\n '     -------------------------------------- 181.6/181.6 kB 5.4 MB/s eta 0:00:00',\n 'Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)',\n '  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/d8/f0/a2ee543a96cc624c35a9086f39b1ed2aa403c6d355dfe47a11ee5c64a164/annotated_types-0.5.0-py3-none-any.whl.metadata',\n '  Downloading annotated_types-0.5.0-py3-none-any.whl.metadata (11 kB)',\n 'Collecting pydantic-core==2.6.3 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)',\n '  Obtaining dependency information for pydantic-core==2.6.3 from https://files.pythonhosted.org/packages/29/37/eb1c5853ecaac79d2dc19be206fd6732fdfa6a6bf705048d0a1046c5fa8d/pydantic_core-2.6.3-cp311-none-win_amd64.whl.metadata',\n '  Downloading pydantic_core-2.6.3-cp311-none-win_amd64.whl.metadata (6.6 kB)',\n 'Collecting typing-extensions>=4.6.1 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)',\n '  Obtaining dependency information for typing-extensions>=4.6.1 from https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl.metadata',\n '  Using cached typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)',\n 'Requirement already satisfied: charset-normalizer<4,>=2 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)',\n 'Requirement already satisfied: idna<4,>=2.5 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)',\n 'Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)',\n 'Requirement already satisfied: certifi>=2017.4.17 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)',\n 'Collecting blis<0.8.0,>=0.7.8 (from thinc<8.2.0,>=8.1.8->spacy)',\n '  Obtaining dependency information for blis<0.8.0,>=0.7.8 from https://files.pythonhosted.org/packages/d3/1a/24c6b7d5445b99e24fe242921b50f8a3469d79a508b9d7831451f423e1db/blis-0.7.10-cp311-cp311-win_amd64.whl.metadata',\n '  Downloading blis-0.7.10-cp311-cp311-win_amd64.whl.metadata (7.6 kB)',\n 'Collecting confection<1.0.0,>=0.0.1 (from thinc<8.2.0,>=8.1.8->spacy)',\n '  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/05/5e/1a56e81e3335ce18f6742539edd2f6ea98bbf477fefc9a4dc5c0694bace4/confection-0.1.1-py3-none-any.whl.metadata',\n '  Downloading confection-0.1.1-py3-none-any.whl.metadata (19 kB)',\n 'Requirement already satisfied: colorama in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)',\n 'Collecting click<9.0.0,>=7.1.1 (from typer<0.10.0,>=0.3.0->spacy)',\n '  Obtaining dependency information for click<9.0.0,>=7.1.1 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata',\n '  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)',\n 'Requirement already satisfied: MarkupSafe>=2.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from jinja2->spacy) (2.1.3)',\n 'Downloading spacy-3.6.1-cp311-cp311-win_amd64.whl (12.0 MB)',\n '   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--',\n '    --------------------------------------- 0.2/12.0 MB 14.7 MB/s eta 0:00:01',\n '    --------------------------------------- 0.3/12.0 MB 3.7 MB/s eta 0:00:04',\n '   -- ------------------------------------- 0.7/12.0 MB 5.2 MB/s eta 0:00:03',\n '   -- ------------------------------------- 0.8/12.0 MB 4.8 MB/s eta 0:00:03',\n '   --- ------------------------------------ 1.0/12.0 MB 4.7 MB/s eta 0:00:03',\n '   ---- ----------------------------------- 1.3/12.0 MB 4.9 MB/s eta 0:00:03',\n '   ----- ---------------------------------- 1.5/12.0 MB 5.0 MB/s eta 0:00:03',\n '   ----- ---------------------------------- 1.5/12.0 MB 5.0 MB/s eta 0:00:03',\n '   ----- ---------------------------------- 1.7/12.0 MB 4.2 MB/s eta 0:00:03',\n '   -------- ------------------------------- 2.5/12.0 MB 5.6 MB/s eta 0:00:02',\n '   -------- ------------------------------- 2.6/12.0 MB 5.4 MB/s eta 0:00:02',\n '   -------- ------------------------------- 2.6/12.0 MB 5.4 MB/s eta 0:00:02',\n '   -------- ------------------------------- 2.6/12.0 MB 5.4 MB/s eta 0:00:02',\n '   -------- ------------------------------- 2.6/12.0 MB 5.4 MB/s eta 0:00:02',\n '   ----------- ---------------------------- 3.6/12.0 MB 5.4 MB/s eta 0:00:02',\n '   ------------ --------------------------- 3.9/12.0 MB 5.3 MB/s eta 0:00:02',\n '   ------------- -------------------------- 4.1/12.0 MB 5.2 MB/s eta 0:00:02',\n '   -------------- ------------------------- 4.2/12.0 MB 5.1 MB/s eta 0:00:02',\n '   --------------- ------------------------ 4.6/12.0 MB 5.2 MB/s eta 0:00:02',\n '   ---------------- ----------------------- 5.0/12.0 MB 5.4 MB/s eta 0:00:02',\n '   ----------------- ---------------------- 5.3/12.0 MB 5.5 MB/s eta 0:00:02',\n '   ------------------ --------------------- 5.5/12.0 MB 5.5 MB/s eta 0:00:02',\n '   ------------------ --------------------- 5.7/12.0 MB 5.4 MB/s eta 0:00:02',\n '   -------------------- ------------------- 6.1/12.0 MB 5.5 MB/s eta 0:00:02',\n '   --------------------- ------------------ 6.4/12.0 MB 5.6 MB/s eta 0:00:02',\n '   ---------------------- ----------------- 6.9/12.0 MB 5.7 MB/s eta 0:00:01',\n '   ------------------------ --------------- 7.3/12.0 MB 5.8 MB/s eta 0:00:01',\n '   ------------------------- -------------- 7.6/12.0 MB 5.9 MB/s eta 0:00:01',\n '   -------------------------- ------------- 8.1/12.0 MB 6.0 MB/s eta 0:00:01',\n '   --------------------------- ------------ 8.4/12.0 MB 6.0 MB/s eta 0:00:01',\n '   ----------------------------- ---------- 8.8/12.0 MB 6.1 MB/s eta 0:00:01',\n '   ------------------------------ --------- 9.1/12.0 MB 6.1 MB/s eta 0:00:01',\n '   ------------------------------- -------- 9.5/12.0 MB 6.2 MB/s eta 0:00:01',\n '   -------------------------------- ------- 9.9/12.0 MB 6.2 MB/s eta 0:00:01',\n '   ---------------------------------- ----- 10.3/12.0 MB 6.3 MB/s eta 0:00:01',\n '   ----------------------------------- ---- 10.7/12.0 MB 6.5 MB/s eta 0:00:01',\n '   ------------------------------------ --- 11.1/12.0 MB 6.7 MB/s eta 0:00:01',\n '   ------------------------------------- -- 11.4/12.0 MB 6.7 MB/s eta 0:00:01',\n '   ---------------------------------------  11.7/12.0 MB 7.2 MB/s eta 0:00:01',\n '   ---------------------------------------  12.0/12.0 MB 7.3 MB/s eta 0:00:01',\n '   ---------------------------------------- 12.0/12.0 MB 7.1 MB/s eta 0:00:00',\n 'Downloading catalogue-2.0.9-py3-none-any.whl (17 kB)',\n 'Using cached numpy-1.25.2-cp311-cp311-win_amd64.whl (15.5 MB)',\n 'Downloading pathy-0.10.2-py3-none-any.whl (48 kB)',\n '   ---------------------------------------- 0.0/48.9 kB ? eta -:--:--',\n '   ---------------------------------------- 48.9/48.9 kB 2.4 MB/s eta 0:00:00',\n 'Downloading pydantic-2.3.0-py3-none-any.whl (374 kB)',\n '   ---------------------------------------- 0.0/374.5 kB ? eta -:--:--',\n '   ----------------------------------- --- 337.9/374.5 kB 10.2 MB/s eta 0:00:01',\n '   --------------------------------------- 374.5/374.5 kB 11.4 MB/s eta 0:00:00',\n 'Downloading pydantic_core-2.6.3-cp311-none-win_amd64.whl (1.7 MB)',\n '   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--',\n '   ------ --------------------------------- 0.3/1.7 MB 17.3 MB/s eta 0:00:01',\n '   ------------------ --------------------- 0.8/1.7 MB 10.5 MB/s eta 0:00:01',\n '   ------------------------ --------------- 1.1/1.7 MB 8.5 MB/s eta 0:00:01',\n '   ---------------------------------- ----- 1.5/1.7 MB 8.7 MB/s eta 0:00:01',\n '   ---------------------------------------- 1.7/1.7 MB 8.6 MB/s eta 0:00:00',\n 'Downloading srsly-2.4.7-cp311-cp311-win_amd64.whl (479 kB)',\n '   ---------------------------------------- 0.0/479.5 kB ? eta -:--:--',\n '   ------------------------------ --------- 368.6/479.5 kB 7.6 MB/s eta 0:00:01',\n '   ---------------------------------------- 479.5/479.5 kB 7.6 MB/s eta 0:00:00',\n 'Downloading thinc-8.1.12-cp311-cp311-win_amd64.whl (1.5 MB)',\n '   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--',\n '   ----- ---------------------------------- 0.2/1.5 MB 13.0 MB/s eta 0:00:01',\n '   ----------------- ---------------------- 0.7/1.5 MB 10.4 MB/s eta 0:00:01',\n '   ---------------------------- ----------- 1.0/1.5 MB 8.2 MB/s eta 0:00:01',\n '   ---------------------------------------  1.5/1.5 MB 8.5 MB/s eta 0:00:01',\n '   ---------------------------------------- 1.5/1.5 MB 8.5 MB/s eta 0:00:00',\n 'Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)',\n 'Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)',\n 'Downloading annotated_types-0.5.0-py3-none-any.whl (11 kB)',\n 'Downloading blis-0.7.10-cp311-cp311-win_amd64.whl (7.4 MB)',\n '   ---------------------------------------- 0.0/7.4 MB ? eta -:--:--',\n '   - -------------------------------------- 0.4/7.4 MB 7.6 MB/s eta 0:00:01',\n '   ---- ----------------------------------- 0.8/7.4 MB 8.3 MB/s eta 0:00:01',\n '   ------ --------------------------------- 1.1/7.4 MB 9.1 MB/s eta 0:00:01',\n '   -------- ------------------------------- 1.5/7.4 MB 8.6 MB/s eta 0:00:01',\n '   ---------- ----------------------------- 1.9/7.4 MB 8.7 MB/s eta 0:00:01',\n '   ------------ --------------------------- 2.3/7.4 MB 8.6 MB/s eta 0:00:01',\n '   ------------- -------------------------- 2.6/7.4 MB 8.1 MB/s eta 0:00:01',\n '   --------------- ------------------------ 2.9/7.4 MB 8.1 MB/s eta 0:00:01',\n '   ----------------- ---------------------- 3.3/7.4 MB 8.0 MB/s eta 0:00:01',\n '   -------------------- ------------------- 3.8/7.4 MB 8.3 MB/s eta 0:00:01',\n '   ---------------------- ----------------- 4.2/7.4 MB 8.3 MB/s eta 0:00:01',\n '   ------------------------ --------------- 4.6/7.4 MB 8.1 MB/s eta 0:00:01',\n '   --------------------------- ------------ 5.1/7.4 MB 8.5 MB/s eta 0:00:01',\n '   ----------------------------- ---------- 5.5/7.4 MB 8.5 MB/s eta 0:00:01',\n '   ------------------------------- -------- 5.8/7.4 MB 8.4 MB/s eta 0:00:01',\n '   --------------------------------- ------ 6.1/7.4 MB 8.3 MB/s eta 0:00:01',\n '   ----------------------------------- ---- 6.5/7.4 MB 8.3 MB/s eta 0:00:01',\n '   ------------------------------------- -- 7.0/7.4 MB 8.4 MB/s eta 0:00:01',\n '   ---------------------------------------  7.4/7.4 MB 8.4 MB/s eta 0:00:01',\n '   ---------------------------------------- 7.4/7.4 MB 8.3 MB/s eta 0:00:00',\n 'Downloading click-8.1.7-py3-none-any.whl (97 kB)',\n '   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--',\n '   ---------------------------------------- 97.9/97.9 kB ? eta 0:00:00',\n 'Downloading confection-0.1.1-py3-none-any.whl (34 kB)',\n 'Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)',\n 'Installing collected packages: cymem, wasabi, typing-extensions, tqdm, spacy-loggers, spacy-legacy, smart-open, numpy, murmurhash, langcodes, click, catalogue, annotated-types, typer, srsly, pydantic-core, preshed, blis, pydantic, pathy, confection, thinc, spacy',\n 'Successfully installed annotated-types-0.5.0 blis-0.7.10 catalogue-2.0.9 click-8.1.7 confection-0.1.1 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 numpy-1.25.2 pathy-0.10.2 preshed-3.0.8 pydantic-2.3.0 pydantic-core-2.6.3 smart-open-6.3.0 spacy-3.6.1 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.7 thinc-8.1.12 tqdm-4.66.1 typer-0.9.0 typing-extensions-4.7.1 wasabi-1.1.2']"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "!! pip install spacy "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T09:51:40.733420400Z",
     "start_time": "2023-09-05T09:50:58.351243800Z"
    }
   },
   "id": "14bc395afb28b85f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['Collecting en-core-web-sm==3.6.0',\n '  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)',\n '     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--',\n '     --------------------------------------- 0.0/12.8 MB 660.6 kB/s eta 0:00:20',\n '     --------------------------------------- 0.0/12.8 MB 660.6 kB/s eta 0:00:20',\n '     --------------------------------------- 0.1/12.8 MB 409.6 kB/s eta 0:00:32',\n '     --------------------------------------- 0.1/12.8 MB 654.9 kB/s eta 0:00:20',\n '      -------------------------------------- 0.2/12.8 MB 841.6 kB/s eta 0:00:15',\n '      --------------------------------------- 0.3/12.8 MB 1.0 MB/s eta 0:00:13',\n '     - -------------------------------------- 0.4/12.8 MB 1.3 MB/s eta 0:00:10',\n '     - -------------------------------------- 0.6/12.8 MB 1.6 MB/s eta 0:00:08',\n '     -- ------------------------------------- 0.8/12.8 MB 2.1 MB/s eta 0:00:06',\n '     --- ------------------------------------ 1.1/12.8 MB 2.4 MB/s eta 0:00:05',\n '     ---- ----------------------------------- 1.5/12.8 MB 3.0 MB/s eta 0:00:04',\n '     ----- ---------------------------------- 1.8/12.8 MB 3.2 MB/s eta 0:00:04',\n '     ----- ---------------------------------- 1.8/12.8 MB 3.2 MB/s eta 0:00:04',\n '     ----- ---------------------------------- 1.8/12.8 MB 3.2 MB/s eta 0:00:04',\n '     ----- ---------------------------------- 1.8/12.8 MB 3.2 MB/s eta 0:00:04',\n '     ----- ---------------------------------- 1.8/12.8 MB 3.2 MB/s eta 0:00:04',\n '     ----- ---------------------------------- 1.8/12.8 MB 3.2 MB/s eta 0:00:04',\n '     ----- ---------------------------------- 1.8/12.8 MB 3.2 MB/s eta 0:00:04',\n '     ------------ --------------------------- 3.9/12.8 MB 4.4 MB/s eta 0:00:03',\n '     ------------ --------------------------- 3.9/12.8 MB 4.4 MB/s eta 0:00:03',\n '     ------------ --------------------------- 4.0/12.8 MB 4.1 MB/s eta 0:00:03',\n '     ------------ --------------------------- 4.0/12.8 MB 4.1 MB/s eta 0:00:03',\n '     ------------ --------------------------- 4.1/12.8 MB 3.9 MB/s eta 0:00:03',\n '     ------------- -------------------------- 4.5/12.8 MB 4.0 MB/s eta 0:00:03',\n '     --------------- ------------------------ 4.9/12.8 MB 4.3 MB/s eta 0:00:02',\n '     ---------------- ----------------------- 5.3/12.8 MB 4.4 MB/s eta 0:00:02',\n '     ----------------- ---------------------- 5.6/12.8 MB 4.5 MB/s eta 0:00:02',\n '     ------------------ --------------------- 6.1/12.8 MB 4.7 MB/s eta 0:00:02',\n '     -------------------- ------------------- 6.5/12.8 MB 4.8 MB/s eta 0:00:02',\n '     --------------------- ------------------ 6.9/12.8 MB 4.9 MB/s eta 0:00:02',\n '     ---------------------- ----------------- 7.3/12.8 MB 5.0 MB/s eta 0:00:02',\n '     ------------------------ --------------- 7.7/12.8 MB 5.2 MB/s eta 0:00:01',\n '     ------------------------- -------------- 8.1/12.8 MB 5.3 MB/s eta 0:00:01',\n '     -------------------------- ------------- 8.4/12.8 MB 5.3 MB/s eta 0:00:01',\n '     --------------------------- ------------ 8.8/12.8 MB 5.4 MB/s eta 0:00:01',\n '     ---------------------------- ----------- 9.3/12.8 MB 5.5 MB/s eta 0:00:01',\n '     ------------------------------ --------- 9.7/12.8 MB 5.6 MB/s eta 0:00:01',\n '     ------------------------------- -------- 10.1/12.8 MB 5.7 MB/s eta 0:00:01',\n '     -------------------------------- ------- 10.5/12.8 MB 6.6 MB/s eta 0:00:01',\n '     ---------------------------------- ----- 10.9/12.8 MB 6.9 MB/s eta 0:00:01',\n '     ----------------------------------- ---- 11.3/12.8 MB 7.0 MB/s eta 0:00:01',\n '     ------------------------------------ --- 11.7/12.8 MB 7.0 MB/s eta 0:00:01',\n '     ------------------------------------- -- 12.0/12.8 MB 9.0 MB/s eta 0:00:01',\n '     -------------------------------------- - 12.3/12.8 MB 8.7 MB/s eta 0:00:01',\n '     ---------------------------------------  12.8/12.8 MB 8.4 MB/s eta 0:00:01',\n '     ---------------------------------------- 12.8/12.8 MB 8.1 MB/s eta 0:00:00',\n 'Requirement already satisfied: spacy<3.7.0,>=3.6.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from en-core-web-sm==3.6.0) (3.6.1)',\n 'Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)',\n 'Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)',\n 'Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)',\n 'Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)',\n 'Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)',\n 'Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)',\n 'Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)',\n 'Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)',\n 'Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)',\n 'Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)',\n 'Requirement already satisfied: pathy>=0.10.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)',\n 'Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.3.0)',\n 'Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)',\n 'Requirement already satisfied: numpy>=1.15.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.25.2)',\n 'Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)',\n 'Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.3.0)',\n 'Requirement already satisfied: jinja2 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)',\n 'Requirement already satisfied: setuptools in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (68.0.0)',\n 'Requirement already satisfied: packaging>=20.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.1)',\n 'Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)',\n 'Requirement already satisfied: annotated-types>=0.4.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.5.0)',\n 'Requirement already satisfied: pydantic-core==2.6.3 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.6.3)',\n 'Requirement already satisfied: typing-extensions>=4.6.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.7.1)',\n 'Requirement already satisfied: charset-normalizer<4,>=2 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.2.0)',\n 'Requirement already satisfied: idna<4,>=2.5 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)',\n 'Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)',\n 'Requirement already satisfied: certifi>=2017.4.17 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)',\n 'Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)',\n 'Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.1)',\n 'Requirement already satisfied: colorama in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.4.6)',\n 'Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)',\n 'Requirement already satisfied: MarkupSafe>=2.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)',\n 'Installing collected packages: en-core-web-sm',\n 'Successfully installed en-core-web-sm-3.6.0',\n '\\x1b[38;5;2m[+] Download and installation successful\\x1b[0m',\n \"You can now load the package via spacy.load('en_core_web_sm')\"]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!! python -m spacy download en_core_web_sm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T09:54:45.460765100Z",
     "start_time": "2023-09-05T09:54:38.773958200Z"
    }
   },
   "id": "9cd9bd9c4ce515fa"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import spacy "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T07:42:43.581815100Z",
     "start_time": "2023-09-07T07:42:37.955945800Z"
    }
   },
   "id": "885d9e488158c560"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T09:54:58.926635600Z",
     "start_time": "2023-09-05T09:54:58.156404Z"
    }
   },
   "id": "5a93c52122cd8e36"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "text = \"Using the part-of-speech tags we extract multiword expression candidates consisting of sequences of zero or more adjectives ADJ followed by nouns NOUN or proper nouns PROPN sequences.\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T09:55:26.336070300Z",
     "start_time": "2023-09-05T09:55:26.317623200Z"
    }
   },
   "id": "260365f4ddf696ab"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "doc=nlp(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T09:55:46.552364900Z",
     "start_time": "2023-09-05T09:55:46.526773600Z"
    }
   },
   "id": "82513f7bd1ff25fe"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part\n",
      "speech tags\n",
      "multiword expression candidates\n",
      "sequences\n",
      "more adjectives ADJ\n",
      "nouns NOUN\n",
      "proper nouns PROPN sequences\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to store multiword expression candidates\n",
    "candidates = []\n",
    "current_candidate = []\n",
    "\n",
    "# Define the allowed POS tags for adjectives and nouns\n",
    "allowed_adjective_tags = {'ADJ'}\n",
    "allowed_noun_tags = {'NOUN', 'PROPN'}\n",
    "\n",
    "# Iterate through the tokens and their POS tags\n",
    "for token in doc:\n",
    "    if token.pos_ in allowed_adjective_tags or token.pos_ in allowed_noun_tags:\n",
    "        # Append the token to the current candidate sequence\n",
    "        current_candidate.append(token.text)\n",
    "    else:\n",
    "        # If the current token is not one of the desired POS tags, check if there's a valid candidate\n",
    "        if current_candidate:\n",
    "            candidates.append(\" \".join(current_candidate))  # Join the tokens to form a candidate\n",
    "            current_candidate = []  # Reset the current candidate\n",
    "\n",
    "# Check if there's a valid candidate at the end of the text\n",
    "if current_candidate:\n",
    "    candidates.append(\" \".join(current_candidate))\n",
    "\n",
    "# Print the multiword expression candidates\n",
    "for candidate in candidates:\n",
    "    print(candidate)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T10:09:38.407703100Z",
     "start_time": "2023-09-05T10:09:37.825999400Z"
    }
   },
   "id": "300991b2c94343da"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate: learning models\n",
      "Sentence: Supervised learning models often perform poorly at low-shot tasks, i.e. tasks for which little labeled data is available for training.\n",
      "\n",
      "Candidate: shot tasks\n",
      "Sentence: Supervised learning models often perform poorly at low-shot tasks, i.e. tasks for which little labeled data is available for training.\n",
      "\n",
      "Candidate: prominent approach\n",
      "Sentence: One prominent approach for improving low-shot learning is to use unsupervised pre-trained neural models.\n",
      "\n",
      "Candidate: shot learning\n",
      "Sentence: One prominent approach for improving low-shot learning is to use unsupervised pre-trained neural models.\n",
      "\n",
      "Candidate: neural models\n",
      "Sentence: One prominent approach for improving low-shot learning is to use unsupervised pre-trained neural models.\n",
      "\n",
      "Candidate: richer supervision\n",
      "Sentence: Another approach is to obtain richer supervision by collecting annotator rationales (explanations supporting label annotations).\n",
      "\n",
      "Candidate: annotator rationales\n",
      "Sentence: Another approach is to obtain richer supervision by collecting annotator rationales (explanations supporting label annotations).\n",
      "\n",
      "Candidate: label annotations\n",
      "Sentence: Another approach is to obtain richer supervision by collecting annotator rationales (explanations supporting label annotations).\n",
      "\n",
      "Candidate: shot text\n",
      "Sentence: In this work, we combine these two approaches to improve low-shot text classification with two novel methods: a simple bag-of-words embedding approach; and a more complex context-aware method, based on the BERT model.\n",
      "\n",
      "Candidate: shot text classification\n",
      "Sentence: In this work, we combine these two approaches to improve low-shot text classification with two novel methods: a simple bag-of-words embedding approach; and a more complex context-aware method, based on the BERT model.\n",
      "\n",
      "Candidate: text classification\n",
      "Sentence: In this work, we combine these two approaches to improve low-shot text classification with two novel methods: a simple bag-of-words embedding approach; and a more complex context-aware method, based on the BERT model.\n",
      "\n",
      "Candidate: novel methods\n",
      "Sentence: In this work, we combine these two approaches to improve low-shot text classification with two novel methods: a simple bag-of-words embedding approach; and a more complex context-aware method, based on the BERT model.\n",
      "\n",
      "Candidate: simple bag\n",
      "Sentence: In this work, we combine these two approaches to improve low-shot text classification with two novel methods: a simple bag-of-words embedding approach; and a more complex context-aware method, based on the BERT model.\n",
      "\n",
      "Candidate: complex context\n",
      "Sentence: In this work, we combine these two approaches to improve low-shot text classification with two novel methods: a simple bag-of-words embedding approach; and a more complex context-aware method, based on the BERT model.\n",
      "\n",
      "Candidate: aware method\n",
      "Sentence: In this work, we combine these two approaches to improve low-shot text classification with two novel methods: a simple bag-of-words embedding approach; and a more complex context-aware method, based on the BERT model.\n",
      "\n",
      "Candidate: BERT model\n",
      "Sentence: In this work, we combine these two approaches to improve low-shot text classification with two novel methods: a simple bag-of-words embedding approach; and a more complex context-aware method, based on the BERT model.\n",
      "\n",
      "Candidate: English text\n",
      "Sentence: In experiments with two English text classification datasets, we demonstrate substantial performance gains from combining pre-training with rationales.\n",
      "\n",
      "Candidate: English text classification\n",
      "Sentence: In experiments with two English text classification datasets, we demonstrate substantial performance gains from combining pre-training with rationales.\n",
      "\n",
      "Candidate: text classification\n",
      "Sentence: In experiments with two English text classification datasets, we demonstrate substantial performance gains from combining pre-training with rationales.\n",
      "\n",
      "Candidate: English text classification datasets\n",
      "Sentence: In experiments with two English text classification datasets, we demonstrate substantial performance gains from combining pre-training with rationales.\n",
      "\n",
      "Candidate: text classification datasets\n",
      "Sentence: In experiments with two English text classification datasets, we demonstrate substantial performance gains from combining pre-training with rationales.\n",
      "\n",
      "Candidate: classification datasets\n",
      "Sentence: In experiments with two English text classification datasets, we demonstrate substantial performance gains from combining pre-training with rationales.\n",
      "\n",
      "Candidate: substantial performance\n",
      "Sentence: In experiments with two English text classification datasets, we demonstrate substantial performance gains from combining pre-training with rationales.\n",
      "\n",
      "Candidate: substantial performance gains\n",
      "Sentence: In experiments with two English text classification datasets, we demonstrate substantial performance gains from combining pre-training with rationales.\n",
      "\n",
      "Candidate: performance gains\n",
      "Sentence: In experiments with two English text classification datasets, we demonstrate substantial performance gains from combining pre-training with rationales.\n",
      "\n",
      "Candidate: pre -\n",
      "Sentence: In experiments with two English text classification datasets, we demonstrate substantial performance gains from combining pre-training with rationales.\n",
      "\n",
      "Candidate: pre - training\n",
      "Sentence: In experiments with two English text classification datasets, we demonstrate substantial performance gains from combining pre-training with rationales.\n",
      "\n",
      "Candidate: - training\n",
      "Sentence: In experiments with two English text classification datasets, we demonstrate substantial performance gains from combining pre-training with rationales.\n",
      "\n",
      "Candidate: simple bag\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: words approach\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: clear top performer\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: top performer\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: few dozen\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: few dozen training\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: dozen training\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: few dozen training instances\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: dozen training instances\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: training instances\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: more complex models\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: complex models\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: more training\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: more training data\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: training data\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: Current dialogue\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: Current dialogue summarization\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: dialogue summarization\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: Current dialogue summarization systems\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: dialogue summarization systems\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: summarization systems\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: general semantic features\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: semantic features\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: powerful dialogue\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: powerful dialogue modeling\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: dialogue modeling\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: powerful dialogue modeling capabilities\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: dialogue modeling capabilities\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: modeling capabilities\n",
      "Sentence: Furthermore, our investigation of a range of train-set sizes reveals that the simple bag-of-words approach is the clear top performer when there are only a few dozen training instances or less, while more complex models, such as BERT or CNN, require more training data to shine\n",
      "Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities.\n",
      "\n",
      "Candidate: domain toolkits\n",
      "Sentence: However, these features are obtained via open-domain toolkits that are dialog-agnostic or heavily relied on human annotations.\n",
      "\n",
      "Candidate: human annotations\n",
      "Sentence: However, these features are obtained via open-domain toolkits that are dialog-agnostic or heavily relied on human annotations.\n",
      "\n",
      "Candidate: conversational response\n",
      "Sentence: In this paper, we show how DialoGPT, a pre-trained model for conversational response generation, can be developed as an unsupervised dialogue annotator, which takes advantage of dialogue background knowledge encoded in DialoGPT.\n",
      "\n",
      "Candidate: conversational response generation\n",
      "Sentence: In this paper, we show how DialoGPT, a pre-trained model for conversational response generation, can be developed as an unsupervised dialogue annotator, which takes advantage of dialogue background knowledge encoded in DialoGPT.\n",
      "\n",
      "Candidate: response generation\n",
      "Sentence: In this paper, we show how DialoGPT, a pre-trained model for conversational response generation, can be developed as an unsupervised dialogue annotator, which takes advantage of dialogue background knowledge encoded in DialoGPT.\n",
      "\n",
      "Candidate: unsupervised dialogue\n",
      "Sentence: In this paper, we show how DialoGPT, a pre-trained model for conversational response generation, can be developed as an unsupervised dialogue annotator, which takes advantage of dialogue background knowledge encoded in DialoGPT.\n",
      "\n",
      "Candidate: unsupervised dialogue annotator\n",
      "Sentence: In this paper, we show how DialoGPT, a pre-trained model for conversational response generation, can be developed as an unsupervised dialogue annotator, which takes advantage of dialogue background knowledge encoded in DialoGPT.\n",
      "\n",
      "Candidate: dialogue annotator\n",
      "Sentence: In this paper, we show how DialoGPT, a pre-trained model for conversational response generation, can be developed as an unsupervised dialogue annotator, which takes advantage of dialogue background knowledge encoded in DialoGPT.\n",
      "\n",
      "Candidate: dialogue background\n",
      "Sentence: In this paper, we show how DialoGPT, a pre-trained model for conversational response generation, can be developed as an unsupervised dialogue annotator, which takes advantage of dialogue background knowledge encoded in DialoGPT.\n",
      "\n",
      "Candidate: dialogue background knowledge\n",
      "Sentence: In this paper, we show how DialoGPT, a pre-trained model for conversational response generation, can be developed as an unsupervised dialogue annotator, which takes advantage of dialogue background knowledge encoded in DialoGPT.\n",
      "\n",
      "Candidate: background knowledge\n",
      "Sentence: In this paper, we show how DialoGPT, a pre-trained model for conversational response generation, can be developed as an unsupervised dialogue annotator, which takes advantage of dialogue background knowledge encoded in DialoGPT.\n",
      "\n",
      "Candidate: dialogue summarization\n",
      "Sentence: We apply DialoGPT to label three types of features on two dialogue summarization datasets, SAMSum and AMI, and employ pre-trained and non pre-trained models as our summarizers.\n",
      "\n",
      "Candidate: dialogue summarization datasets\n",
      "Sentence: We apply DialoGPT to label three types of features on two dialogue summarization datasets, SAMSum and AMI, and employ pre-trained and non pre-trained models as our summarizers.\n",
      "\n",
      "Candidate: summarization datasets\n",
      "Sentence: We apply DialoGPT to label three types of features on two dialogue summarization datasets, SAMSum and AMI, and employ pre-trained and non pre-trained models as our summarizers.\n",
      "\n",
      "Candidate: Experimental results\n",
      "Sentence: Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset\n",
      "It is hard to create consistent ground truth data for interest points in natural images, since interest points are hard to define clearly and consistently for a human annotator.\n",
      "\n",
      "Candidate: remarkable improvements\n",
      "Sentence: Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset\n",
      "It is hard to create consistent ground truth data for interest points in natural images, since interest points are hard to define clearly and consistently for a human annotator.\n",
      "\n",
      "Candidate: new state\n",
      "Sentence: Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset\n",
      "It is hard to create consistent ground truth data for interest points in natural images, since interest points are hard to define clearly and consistently for a human annotator.\n",
      "\n",
      "Candidate: art performance\n",
      "Sentence: Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset\n",
      "It is hard to create consistent ground truth data for interest points in natural images, since interest points are hard to define clearly and consistently for a human annotator.\n",
      "\n",
      "Candidate: SAMSum dataset\n",
      "Sentence: Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset\n",
      "It is hard to create consistent ground truth data for interest points in natural images, since interest points are hard to define clearly and consistently for a human annotator.\n",
      "\n",
      "Candidate: consistent ground\n",
      "Sentence: Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset\n",
      "It is hard to create consistent ground truth data for interest points in natural images, since interest points are hard to define clearly and consistently for a human annotator.\n",
      "\n",
      "Candidate: consistent ground truth\n",
      "Sentence: Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset\n",
      "It is hard to create consistent ground truth data for interest points in natural images, since interest points are hard to define clearly and consistently for a human annotator.\n",
      "\n",
      "Candidate: ground truth\n",
      "Sentence: Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset\n",
      "It is hard to create consistent ground truth data for interest points in natural images, since interest points are hard to define clearly and consistently for a human annotator.\n",
      "\n",
      "Candidate: consistent ground truth data\n",
      "Sentence: Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset\n",
      "It is hard to create consistent ground truth data for interest points in natural images, since interest points are hard to define clearly and consistently for a human annotator.\n",
      "\n",
      "Candidate: ground truth data\n",
      "Sentence: Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset\n",
      "It is hard to create consistent ground truth data for interest points in natural images, since interest points are hard to define clearly and consistently for a human annotator.\n",
      "\n",
      "Candidate: truth data\n",
      "Sentence: Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset\n",
      "It is hard to create consistent ground truth data for interest points in natural images, since interest points are hard to define clearly and consistently for a human annotator.\n",
      "\n",
      "Candidate: interest points\n",
      "Sentence: Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset\n",
      "It is hard to create consistent ground truth data for interest points in natural images, since interest points are hard to define clearly and consistently for a human annotator.\n",
      "\n",
      "Candidate: natural images\n",
      "Sentence: Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset\n",
      "It is hard to create consistent ground truth data for interest points in natural images, since interest points are hard to define clearly and consistently for a human annotator.\n",
      "\n",
      "Candidate: interest points\n",
      "Sentence: Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset\n",
      "It is hard to create consistent ground truth data for interest points in natural images, since interest points are hard to define clearly and consistently for a human annotator.\n",
      "\n",
      "Candidate: human annotator\n",
      "Sentence: Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset\n",
      "It is hard to create consistent ground truth data for interest points in natural images, since interest points are hard to define clearly and consistently for a human annotator.\n",
      "\n",
      "Candidate: interest point\n",
      "Sentence: This makes interest point detectors non-trivial to build.\n",
      "\n",
      "Candidate: interest point detectors\n",
      "Sentence: This makes interest point detectors non-trivial to build.\n",
      "\n",
      "Candidate: point detectors\n",
      "Sentence: This makes interest point detectors non-trivial to build.\n",
      "\n",
      "Candidate: unsupervised deep learning\n",
      "Sentence: In this work, we introduce an unsupervised deep learning-based interest point detector and descriptor.\n",
      "\n",
      "Candidate: deep learning\n",
      "Sentence: In this work, we introduce an unsupervised deep learning-based interest point detector and descriptor.\n",
      "\n",
      "Candidate: interest point\n",
      "Sentence: In this work, we introduce an unsupervised deep learning-based interest point detector and descriptor.\n",
      "\n",
      "Candidate: interest point detector\n",
      "Sentence: In this work, we introduce an unsupervised deep learning-based interest point detector and descriptor.\n",
      "\n",
      "Candidate: point detector\n",
      "Sentence: In this work, we introduce an unsupervised deep learning-based interest point detector and descriptor.\n",
      "\n",
      "Candidate: siamese network\n",
      "Sentence: Using a self-supervised approach, we utilize a siamese network and a novel loss function that enables interest point scores and positions to be learned automatically.\n",
      "\n",
      "Candidate: novel loss\n",
      "Sentence: Using a self-supervised approach, we utilize a siamese network and a novel loss function that enables interest point scores and positions to be learned automatically.\n",
      "\n",
      "Candidate: novel loss function\n",
      "Sentence: Using a self-supervised approach, we utilize a siamese network and a novel loss function that enables interest point scores and positions to be learned automatically.\n",
      "\n",
      "Candidate: loss function\n",
      "Sentence: Using a self-supervised approach, we utilize a siamese network and a novel loss function that enables interest point scores and positions to be learned automatically.\n",
      "\n",
      "Candidate: interest point\n",
      "Sentence: Using a self-supervised approach, we utilize a siamese network and a novel loss function that enables interest point scores and positions to be learned automatically.\n",
      "\n",
      "Candidate: interest point scores\n",
      "Sentence: Using a self-supervised approach, we utilize a siamese network and a novel loss function that enables interest point scores and positions to be learned automatically.\n",
      "\n",
      "Candidate: point scores\n",
      "Sentence: Using a self-supervised approach, we utilize a siamese network and a novel loss function that enables interest point scores and positions to be learned automatically.\n",
      "\n",
      "Candidate: interest point\n",
      "Sentence: The resulting interest point detector and descriptor is UnsuperPoint.\n",
      "\n",
      "Candidate: interest point detector\n",
      "Sentence: The resulting interest point detector and descriptor is UnsuperPoint.\n",
      "\n",
      "Candidate: point detector\n",
      "Sentence: The resulting interest point detector and descriptor is UnsuperPoint.\n",
      "\n",
      "Candidate: point positions\n",
      "Sentence: We use regression of point positions to 1) make UnsuperPoint end-to-end trainable and 2) to incorporate non-maximum suppression in the model.\n",
      "\n",
      "Candidate: non - maximum suppression\n",
      "Sentence: We use regression of point positions to 1) make UnsuperPoint end-to-end trainable and 2) to incorporate non-maximum suppression in the model.\n",
      "\n",
      "Candidate: - maximum suppression\n",
      "Sentence: We use regression of point positions to 1) make UnsuperPoint end-to-end trainable and 2) to incorporate non-maximum suppression in the model.\n",
      "\n",
      "Candidate: maximum suppression\n",
      "Sentence: We use regression of point positions to 1) make UnsuperPoint end-to-end trainable and 2) to incorporate non-maximum suppression in the model.\n",
      "\n",
      "Candidate: most trainable detectors\n",
      "Sentence: Unlike most trainable detectors, it requires no generation of pseudo ground truth points, no structure-from-motion-generated representations and the model is learned from only one round of training.\n",
      "\n",
      "Candidate: trainable detectors\n",
      "Sentence: Unlike most trainable detectors, it requires no generation of pseudo ground truth points, no structure-from-motion-generated representations and the model is learned from only one round of training.\n",
      "\n",
      "Candidate: pseudo ground\n",
      "Sentence: Unlike most trainable detectors, it requires no generation of pseudo ground truth points, no structure-from-motion-generated representations and the model is learned from only one round of training.\n",
      "\n",
      "Candidate: pseudo ground truth\n",
      "Sentence: Unlike most trainable detectors, it requires no generation of pseudo ground truth points, no structure-from-motion-generated representations and the model is learned from only one round of training.\n",
      "\n",
      "Candidate: ground truth\n",
      "Sentence: Unlike most trainable detectors, it requires no generation of pseudo ground truth points, no structure-from-motion-generated representations and the model is learned from only one round of training.\n",
      "\n",
      "Candidate: pseudo ground truth points\n",
      "Sentence: Unlike most trainable detectors, it requires no generation of pseudo ground truth points, no structure-from-motion-generated representations and the model is learned from only one round of training.\n",
      "\n",
      "Candidate: ground truth points\n",
      "Sentence: Unlike most trainable detectors, it requires no generation of pseudo ground truth points, no structure-from-motion-generated representations and the model is learned from only one round of training.\n",
      "\n",
      "Candidate: truth points\n",
      "Sentence: Unlike most trainable detectors, it requires no generation of pseudo ground truth points, no structure-from-motion-generated representations and the model is learned from only one round of training.\n",
      "\n",
      "Candidate: novel loss\n",
      "Sentence: Furthermore, we introduce a novel loss function to regularize network predictions to be uniformly distributed.\n",
      "\n",
      "Candidate: novel loss function\n",
      "Sentence: Furthermore, we introduce a novel loss function to regularize network predictions to be uniformly distributed.\n",
      "\n",
      "Candidate: loss function\n",
      "Sentence: Furthermore, we introduce a novel loss function to regularize network predictions to be uniformly distributed.\n",
      "\n",
      "Candidate: network predictions\n",
      "Sentence: Furthermore, we introduce a novel loss function to regularize network predictions to be uniformly distributed.\n",
      "\n",
      "Candidate: art performance\n",
      "Sentence: UnsuperPoint runs in real-time with 323 frames per second (fps) at a resolution of $224\\times320$ and 90 fps at $480\\times640$. It is comparable or better than state-of-the-art performance when measured for speed, repeatability, localization, matching score and homography estimation on the HPatch dataset.\n",
      "\n",
      "\n",
      "Candidate: homography estimation\n",
      "Sentence: UnsuperPoint runs in real-time with 323 frames per second (fps) at a resolution of $224\\times320$ and 90 fps at $480\\times640$. It is comparable or better than state-of-the-art performance when measured for speed, repeatability, localization, matching score and homography estimation on the HPatch dataset.\n",
      "\n",
      "\n",
      "Candidate: HPatch dataset\n",
      "Sentence: UnsuperPoint runs in real-time with 323 frames per second (fps) at a resolution of $224\\times320$ and 90 fps at $480\\times640$. It is comparable or better than state-of-the-art performance when measured for speed, repeatability, localization, matching score and homography estimation on the HPatch dataset.\n",
      "\n",
      "\n",
      "Candidate: Word Sense\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: Word Sense Disambiguation\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: Sense Disambiguation\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: toughest problems\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: verb disambiguation\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: high degree\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: fine grained senses\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: grained senses\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: deep verb hierarchy\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: verb hierarchy\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: low inter\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: low inter annotator\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: inter annotator\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: low inter annotator agreement\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: inter annotator agreement\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: annotator agreement\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: verb sense\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: verb sense annotation\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: sense annotation\n",
      "Sentence: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation.\n",
      "\n",
      "Candidate: Unsupervised WSD\n",
      "Sentence: Unsupervised WSD has received widespread attention, but has performed poorly, specially on verbs.\n",
      "\n",
      "Candidate: widespread attention\n",
      "Sentence: Unsupervised WSD has received widespread attention, but has performed poorly, specially on verbs.\n",
      "\n",
      "Candidate: unsupervised bilingual EM\n",
      "Sentence: Recently an unsupervised bilingual EM based algorithm has been proposed, which makes use only of the raw counts of the translations in comparable corpora (Marathi and Hindi).\n",
      "\n",
      "Candidate: bilingual EM\n",
      "Sentence: Recently an unsupervised bilingual EM based algorithm has been proposed, which makes use only of the raw counts of the translations in comparable corpora (Marathi and Hindi).\n",
      "\n",
      "Candidate: raw counts\n",
      "Sentence: Recently an unsupervised bilingual EM based algorithm has been proposed, which makes use only of the raw counts of the translations in comparable corpora (Marathi and Hindi).\n",
      "\n",
      "Candidate: comparable corpora\n",
      "Sentence: Recently an unsupervised bilingual EM based algorithm has been proposed, which makes use only of the raw counts of the translations in comparable corpora (Marathi and Hindi).\n",
      "\n",
      "Candidate: accuracy level\n",
      "Sentence: But the performance of this approach is poor on verbs with accuracy level at 25-38%.\n",
      "\n",
      "Candidate: semantic relatedness\n",
      "Sentence: We suggest a modification to this mentioned formulation, using context and semantic relatedness of neighboring words.\n",
      "\n",
      "Candidate: neighboring words\n",
      "Sentence: We suggest a modification to this mentioned formulation, using context and semantic relatedness of neighboring words.\n",
      "\n",
      "Candidate: verb WSD\n",
      "Sentence: An improvement of 17% 35% in the accuracy of verb WSD is obtained compared to the existing EM based approach.\n",
      "\n",
      "Candidate: general note\n",
      "Sentence: On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization.\n",
      "\n",
      "\n",
      "Candidate: unsupervised WSD\n",
      "Sentence: On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization.\n",
      "\n",
      "\n",
      "Candidate: context aware expectation\n",
      "Sentence: On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization.\n",
      "\n",
      "\n",
      "Candidate: aware expectation\n",
      "Sentence: On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization.\n",
      "\n",
      "\n",
      "Candidate: context aware expectation maximization\n",
      "Sentence: On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization.\n",
      "\n",
      "\n",
      "Candidate: aware expectation maximization\n",
      "Sentence: On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization.\n",
      "\n",
      "\n",
      "Candidate: expectation maximization\n",
      "Sentence: On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization.\n",
      "\n",
      "\n",
      "Candidate: Unsupervised learning\n",
      "Sentence: Unsupervised learning of relative visual attributes is important because it is often infeasible for a human annotator to predefine and manually label all the relative attributes in large datasets.\n",
      "\n",
      "Candidate: relative visual attributes\n",
      "Sentence: Unsupervised learning of relative visual attributes is important because it is often infeasible for a human annotator to predefine and manually label all the relative attributes in large datasets.\n",
      "\n",
      "Candidate: visual attributes\n",
      "Sentence: Unsupervised learning of relative visual attributes is important because it is often infeasible for a human annotator to predefine and manually label all the relative attributes in large datasets.\n",
      "\n",
      "Candidate: human annotator\n",
      "Sentence: Unsupervised learning of relative visual attributes is important because it is often infeasible for a human annotator to predefine and manually label all the relative attributes in large datasets.\n",
      "\n",
      "Candidate: relative attributes\n",
      "Sentence: Unsupervised learning of relative visual attributes is important because it is often infeasible for a human annotator to predefine and manually label all the relative attributes in large datasets.\n",
      "\n",
      "Candidate: large datasets\n",
      "Sentence: Unsupervised learning of relative visual attributes is important because it is often infeasible for a human annotator to predefine and manually label all the relative attributes in large datasets.\n",
      "\n",
      "Candidate: relative visual attributes\n",
      "Sentence: We propose a method for learning relative visual attributes given a set of images for each training class.\n",
      "\n",
      "Candidate: visual attributes\n",
      "Sentence: We propose a method for learning relative visual attributes given a set of images for each training class.\n",
      "\n",
      "Candidate: training class\n",
      "Sentence: We propose a method for learning relative visual attributes given a set of images for each training class.\n",
      "\n",
      "Candidate: integer programming\n",
      "Sentence: We formulate the learning as a mixed-integer programming problem and propose an efficient algorithm to solve it approximately.\n",
      "\n",
      "Candidate: integer programming problem\n",
      "Sentence: We formulate the learning as a mixed-integer programming problem and propose an efficient algorithm to solve it approximately.\n",
      "\n",
      "Candidate: programming problem\n",
      "Sentence: We formulate the learning as a mixed-integer programming problem and propose an efficient algorithm to solve it approximately.\n",
      "\n",
      "Candidate: efficient algorithm\n",
      "Sentence: We formulate the learning as a mixed-integer programming problem and propose an efficient algorithm to solve it approximately.\n",
      "\n",
      "Candidate: good generalization\n",
      "Sentence: Experiments show that the learned attributes can provide good generalization and tend to be more discriminative than hand-labeled relative attributes.\n",
      "\n",
      "Candidate: relative attributes\n",
      "Sentence: Experiments show that the learned attributes can provide good generalization and tend to be more discriminative than hand-labeled relative attributes.\n",
      "\n",
      "Candidate: explicit names\n",
      "Sentence: While in the unsupervised setting the learned attributes do not have explicit names, many are highly correlated with human annotated attributes and this demonstrates that our method is able to discover relative attributes automatically.\n",
      "\n",
      "\n",
      "Candidate: human annotated attributes\n",
      "Sentence: While in the unsupervised setting the learned attributes do not have explicit names, many are highly correlated with human annotated attributes and this demonstrates that our method is able to discover relative attributes automatically.\n",
      "\n",
      "\n",
      "Candidate: annotated attributes\n",
      "Sentence: While in the unsupervised setting the learned attributes do not have explicit names, many are highly correlated with human annotated attributes and this demonstrates that our method is able to discover relative attributes automatically.\n",
      "\n",
      "\n",
      "Candidate: relative attributes\n",
      "Sentence: While in the unsupervised setting the learned attributes do not have explicit names, many are highly correlated with human annotated attributes and this demonstrates that our method is able to discover relative attributes automatically.\n",
      "\n",
      "\n",
      "Candidate: Unsupervised Domain\n",
      "Sentence: Unsupervised Domain Adaptation (UDA) for semantic segmentation has been actively studied to mitigate the domain gap between label-rich source data and unlabeled target data.\n",
      "\n",
      "Candidate: Unsupervised Domain Adaptation\n",
      "Sentence: Unsupervised Domain Adaptation (UDA) for semantic segmentation has been actively studied to mitigate the domain gap between label-rich source data and unlabeled target data.\n",
      "\n",
      "Candidate: Domain Adaptation\n",
      "Sentence: Unsupervised Domain Adaptation (UDA) for semantic segmentation has been actively studied to mitigate the domain gap between label-rich source data and unlabeled target data.\n",
      "\n",
      "Candidate: semantic segmentation\n",
      "Sentence: Unsupervised Domain Adaptation (UDA) for semantic segmentation has been actively studied to mitigate the domain gap between label-rich source data and unlabeled target data.\n",
      "\n",
      "Candidate: domain gap\n",
      "Sentence: Unsupervised Domain Adaptation (UDA) for semantic segmentation has been actively studied to mitigate the domain gap between label-rich source data and unlabeled target data.\n",
      "\n",
      "Candidate: rich source\n",
      "Sentence: Unsupervised Domain Adaptation (UDA) for semantic segmentation has been actively studied to mitigate the domain gap between label-rich source data and unlabeled target data.\n",
      "\n",
      "Candidate: rich source data\n",
      "Sentence: Unsupervised Domain Adaptation (UDA) for semantic segmentation has been actively studied to mitigate the domain gap between label-rich source data and unlabeled target data.\n",
      "\n",
      "Candidate: source data\n",
      "Sentence: Unsupervised Domain Adaptation (UDA) for semantic segmentation has been actively studied to mitigate the domain gap between label-rich source data and unlabeled target data.\n",
      "\n",
      "Candidate: unlabeled target\n",
      "Sentence: Unsupervised Domain Adaptation (UDA) for semantic segmentation has been actively studied to mitigate the domain gap between label-rich source data and unlabeled target data.\n",
      "\n",
      "Candidate: unlabeled target data\n",
      "Sentence: Unsupervised Domain Adaptation (UDA) for semantic segmentation has been actively studied to mitigate the domain gap between label-rich source data and unlabeled target data.\n",
      "\n",
      "Candidate: target data\n",
      "Sentence: Unsupervised Domain Adaptation (UDA) for semantic segmentation has been actively studied to mitigate the domain gap between label-rich source data and unlabeled target data.\n",
      "\n",
      "Candidate: long way\n",
      "Sentence: Despite these efforts, UDA still has a long way to go to reach the fully supervised performance.\n",
      "\n",
      "Candidate: supervised performance\n",
      "Sentence: Despite these efforts, UDA still has a long way to go to reach the fully supervised performance.\n",
      "\n",
      "Candidate: loop approach\n",
      "Sentence: To this end, we propose a Labeling Only if Required strategy, LabOR, where we introduce a human-in-the-loop approach to adaptively give scarce labels to points that a UDA model is uncertain about.\n",
      "\n",
      "Candidate: scarce labels\n",
      "Sentence: To this end, we propose a Labeling Only if Required strategy, LabOR, where we introduce a human-in-the-loop approach to adaptively give scarce labels to points that a UDA model is uncertain about.\n",
      "\n",
      "Candidate: UDA model\n",
      "Sentence: To this end, we propose a Labeling Only if Required strategy, LabOR, where we introduce a human-in-the-loop approach to adaptively give scarce labels to points that a UDA model is uncertain about.\n",
      "\n",
      "Candidate: uncertain points\n",
      "Sentence: In order to find the uncertain points, we generate an inconsistency mask using the proposed adaptive pixel selector and we label these segment-based regions to achieve near supervised performance with only a small fraction (about 2.2%) ground truth points, which we call \"Segment based Pixel-Labeling (SPL).\"\n",
      "\n",
      "Candidate: inconsistency mask\n",
      "Sentence: In order to find the uncertain points, we generate an inconsistency mask using the proposed adaptive pixel selector and we label these segment-based regions to achieve near supervised performance with only a small fraction (about 2.2%) ground truth points, which we call \"Segment based Pixel-Labeling (SPL).\"\n",
      "\n",
      "Candidate: adaptive pixel\n",
      "Sentence: In order to find the uncertain points, we generate an inconsistency mask using the proposed adaptive pixel selector and we label these segment-based regions to achieve near supervised performance with only a small fraction (about 2.2%) ground truth points, which we call \"Segment based Pixel-Labeling (SPL).\"\n",
      "\n",
      "Candidate: adaptive pixel selector\n",
      "Sentence: In order to find the uncertain points, we generate an inconsistency mask using the proposed adaptive pixel selector and we label these segment-based regions to achieve near supervised performance with only a small fraction (about 2.2%) ground truth points, which we call \"Segment based Pixel-Labeling (SPL).\"\n",
      "\n",
      "Candidate: pixel selector\n",
      "Sentence: In order to find the uncertain points, we generate an inconsistency mask using the proposed adaptive pixel selector and we label these segment-based regions to achieve near supervised performance with only a small fraction (about 2.2%) ground truth points, which we call \"Segment based Pixel-Labeling (SPL).\"\n",
      "\n",
      "Candidate: supervised performance\n",
      "Sentence: In order to find the uncertain points, we generate an inconsistency mask using the proposed adaptive pixel selector and we label these segment-based regions to achieve near supervised performance with only a small fraction (about 2.2%) ground truth points, which we call \"Segment based Pixel-Labeling (SPL).\"\n",
      "\n",
      "Candidate: small fraction\n",
      "Sentence: In order to find the uncertain points, we generate an inconsistency mask using the proposed adaptive pixel selector and we label these segment-based regions to achieve near supervised performance with only a small fraction (about 2.2%) ground truth points, which we call \"Segment based Pixel-Labeling (SPL).\"\n",
      "\n",
      "Candidate: ground truth\n",
      "Sentence: In order to find the uncertain points, we generate an inconsistency mask using the proposed adaptive pixel selector and we label these segment-based regions to achieve near supervised performance with only a small fraction (about 2.2%) ground truth points, which we call \"Segment based Pixel-Labeling (SPL).\"\n",
      "\n",
      "Candidate: ground truth points\n",
      "Sentence: In order to find the uncertain points, we generate an inconsistency mask using the proposed adaptive pixel selector and we label these segment-based regions to achieve near supervised performance with only a small fraction (about 2.2%) ground truth points, which we call \"Segment based Pixel-Labeling (SPL).\"\n",
      "\n",
      "Candidate: truth points\n",
      "Sentence: In order to find the uncertain points, we generate an inconsistency mask using the proposed adaptive pixel selector and we label these segment-based regions to achieve near supervised performance with only a small fraction (about 2.2%) ground truth points, which we call \"Segment based Pixel-Labeling (SPL).\"\n",
      "\n",
      "Candidate: human annotator\n",
      "Sentence: To further reduce the efforts of the human annotator, we also propose \"Point based Pixel-Labeling (PPL),\" which finds the most representative points for labeling within the generated inconsistency mask.\n",
      "\n",
      "Candidate: representative points\n",
      "Sentence: To further reduce the efforts of the human annotator, we also propose \"Point based Pixel-Labeling (PPL),\" which finds the most representative points for labeling within the generated inconsistency mask.\n",
      "\n",
      "Candidate: inconsistency mask\n",
      "Sentence: To further reduce the efforts of the human annotator, we also propose \"Point based Pixel-Labeling (PPL),\" which finds the most representative points for labeling within the generated inconsistency mask.\n",
      "\n",
      "Candidate: % segment\n",
      "Sentence: This reduces efforts from 2.2% segment label â†’ 40 points label while minimizing performance degradation.\n",
      "\n",
      "Candidate: % segment label\n",
      "Sentence: This reduces efforts from 2.2% segment label â†’ 40 points label while minimizing performance degradation.\n",
      "\n",
      "Candidate: segment label\n",
      "Sentence: This reduces efforts from 2.2% segment label â†’ 40 points label while minimizing performance degradation.\n",
      "\n",
      "Candidate: % segment label â†\n",
      "Sentence: This reduces efforts from 2.2% segment label â†’ 40 points label while minimizing performance degradation.\n",
      "\n",
      "Candidate: segment label â†\n",
      "Sentence: This reduces efforts from 2.2% segment label â†’ 40 points label while minimizing performance degradation.\n",
      "\n",
      "Candidate: label â†\n",
      "Sentence: This reduces efforts from 2.2% segment label â†’ 40 points label while minimizing performance degradation.\n",
      "\n",
      "Candidate: points label\n",
      "Sentence: This reduces efforts from 2.2% segment label â†’ 40 points label while minimizing performance degradation.\n",
      "\n",
      "Candidate: performance degradation\n",
      "Sentence: This reduces efforts from 2.2% segment label â†’ 40 points label while minimizing performance degradation.\n",
      "\n",
      "Candidate: extensive experimentation\n",
      "Sentence: Through extensive experimentation, we show the advantages of this new framework for domain adaptive semantic segmentation while minimizing human labor costs.\n",
      "\n",
      "\n",
      "Candidate: new framework\n",
      "Sentence: Through extensive experimentation, we show the advantages of this new framework for domain adaptive semantic segmentation while minimizing human labor costs.\n",
      "\n",
      "\n",
      "Candidate: domain adaptive semantic segmentation\n",
      "Sentence: Through extensive experimentation, we show the advantages of this new framework for domain adaptive semantic segmentation while minimizing human labor costs.\n",
      "\n",
      "\n",
      "Candidate: adaptive semantic segmentation\n",
      "Sentence: Through extensive experimentation, we show the advantages of this new framework for domain adaptive semantic segmentation while minimizing human labor costs.\n",
      "\n",
      "\n",
      "Candidate: semantic segmentation\n",
      "Sentence: Through extensive experimentation, we show the advantages of this new framework for domain adaptive semantic segmentation while minimizing human labor costs.\n",
      "\n",
      "\n",
      "Candidate: human labor\n",
      "Sentence: Through extensive experimentation, we show the advantages of this new framework for domain adaptive semantic segmentation while minimizing human labor costs.\n",
      "\n",
      "\n",
      "Candidate: human labor costs\n",
      "Sentence: Through extensive experimentation, we show the advantages of this new framework for domain adaptive semantic segmentation while minimizing human labor costs.\n",
      "\n",
      "\n",
      "Candidate: labor costs\n",
      "Sentence: Through extensive experimentation, we show the advantages of this new framework for domain adaptive semantic segmentation while minimizing human labor costs.\n",
      "\n",
      "\n",
      "Candidate: Non - expert annotation\n",
      "Sentence: Non-expert annotation services like Amazonâ€™s Mechanical Turk (AMT) are cheap and fast ways to evaluate systems and provide categorical annotations for training data.\n",
      "\n",
      "Candidate: - expert annotation\n",
      "Sentence: Non-expert annotation services like Amazonâ€™s Mechanical Turk (AMT) are cheap and fast ways to evaluate systems and provide categorical annotations for training data.\n",
      "\n",
      "Candidate: expert annotation\n",
      "Sentence: Non-expert annotation services like Amazonâ€™s Mechanical Turk (AMT) are cheap and fast ways to evaluate systems and provide categorical annotations for training data.\n",
      "\n",
      "Candidate: Non - expert annotation services\n",
      "Sentence: Non-expert annotation services like Amazonâ€™s Mechanical Turk (AMT) are cheap and fast ways to evaluate systems and provide categorical annotations for training data.\n",
      "\n",
      "Candidate: - expert annotation services\n",
      "Sentence: Non-expert annotation services like Amazonâ€™s Mechanical Turk (AMT) are cheap and fast ways to evaluate systems and provide categorical annotations for training data.\n",
      "\n",
      "Candidate: expert annotation services\n",
      "Sentence: Non-expert annotation services like Amazonâ€™s Mechanical Turk (AMT) are cheap and fast ways to evaluate systems and provide categorical annotations for training data.\n",
      "\n",
      "Candidate: annotation services\n",
      "Sentence: Non-expert annotation services like Amazonâ€™s Mechanical Turk (AMT) are cheap and fast ways to evaluate systems and provide categorical annotations for training data.\n",
      "\n",
      "Candidate: Mechanical Turk\n",
      "Sentence: Non-expert annotation services like Amazonâ€™s Mechanical Turk (AMT) are cheap and fast ways to evaluate systems and provide categorical annotations for training data.\n",
      "\n",
      "Candidate: fast ways\n",
      "Sentence: Non-expert annotation services like Amazonâ€™s Mechanical Turk (AMT) are cheap and fast ways to evaluate systems and provide categorical annotations for training data.\n",
      "\n",
      "Candidate: categorical annotations\n",
      "Sentence: Non-expert annotation services like Amazonâ€™s Mechanical Turk (AMT) are cheap and fast ways to evaluate systems and provide categorical annotations for training data.\n",
      "\n",
      "Candidate: training data\n",
      "Sentence: Non-expert annotation services like Amazonâ€™s Mechanical Turk (AMT) are cheap and fast ways to evaluate systems and provide categorical annotations for training data.\n",
      "\n",
      "Candidate: bad labels\n",
      "Sentence: Unfortunately, some annotators choose bad labels in order to maximize their pay.\n",
      "\n",
      "Candidate: Manual identification\n",
      "Sentence: Manual identification is tedious, so we experiment with an item-response model.\n",
      "\n",
      "Candidate: response model\n",
      "Sentence: Manual identification is tedious, so we experiment with an item-response model.\n",
      "\n",
      "Candidate: unsupervised fashion\n",
      "Sentence: It learns in an unsupervised fashion to a) identify which annotators are trustworthy and b) predict the correct underlying labels.\n",
      "\n",
      "Candidate: correct underlying labels\n",
      "Sentence: It learns in an unsupervised fashion to a) identify which annotators are trustworthy and b) predict the correct underlying labels.\n",
      "\n",
      "Candidate: underlying labels\n",
      "Sentence: It learns in an unsupervised fashion to a) identify which annotators are trustworthy and b) predict the correct underlying labels.\n",
      "\n",
      "Candidate: complex state\n",
      "Sentence: We match performance of more complex state-of-the-art systems and perform well even under adversarial conditions.\n",
      "\n",
      "Candidate: art systems\n",
      "Sentence: We match performance of more complex state-of-the-art systems and perform well even under adversarial conditions.\n",
      "\n",
      "Candidate: adversarial conditions\n",
      "Sentence: We match performance of more complex state-of-the-art systems and perform well even under adversarial conditions.\n",
      "\n",
      "Candidate: considerable improvements\n",
      "Sentence: We show considerable improvements over standard baselines, both for predicted label accuracy and trustworthiness estimates.\n",
      "\n",
      "Candidate: standard baselines\n",
      "Sentence: We show considerable improvements over standard baselines, both for predicted label accuracy and trustworthiness estimates.\n",
      "\n",
      "Candidate: label accuracy\n",
      "Sentence: We show considerable improvements over standard baselines, both for predicted label accuracy and trustworthiness estimates.\n",
      "\n",
      "Candidate: trustworthiness estimates\n",
      "Sentence: We show considerable improvements over standard baselines, both for predicted label accuracy and trustworthiness estimates.\n",
      "\n",
      "Candidate: model parameters\n",
      "Sentence: The latter can be further improved by introducing a prior on model parameters and using Variational Bayes inference.\n",
      "\n",
      "Candidate: Variational Bayes\n",
      "Sentence: The latter can be further improved by introducing a prior on model parameters and using Variational Bayes inference.\n",
      "\n",
      "Candidate: Variational Bayes inference\n",
      "Sentence: The latter can be further improved by introducing a prior on model parameters and using Variational Bayes inference.\n",
      "\n",
      "Candidate: Bayes inference\n",
      "Sentence: The latter can be further improved by introducing a prior on model parameters and using Variational Bayes inference.\n",
      "\n",
      "Candidate: higher accuracy\n",
      "Sentence: Additionally, we can achieve even higher accuracy by focusing on the instances our model is most confident in (trading in some recall), and by incorporating annotated control instances.\n",
      "\n",
      "Candidate: annotated control\n",
      "Sentence: Additionally, we can achieve even higher accuracy by focusing on the instances our model is most confident in (trading in some recall), and by incorporating annotated control instances.\n",
      "\n",
      "Candidate: annotated control instances\n",
      "Sentence: Additionally, we can achieve even higher accuracy by focusing on the instances our model is most confident in (trading in some recall), and by incorporating annotated control instances.\n",
      "\n",
      "Candidate: control instances\n",
      "Sentence: Additionally, we can achieve even higher accuracy by focusing on the instances our model is most confident in (trading in some recall), and by incorporating annotated control instances.\n",
      "\n",
      "Candidate: Multi -\n",
      "Sentence: Our system, MACE (Multi-Annotator Competence Estimation), is available for download 1 .\n",
      "\n",
      "\n",
      "Candidate: Multi - Annotator\n",
      "Sentence: Our system, MACE (Multi-Annotator Competence Estimation), is available for download 1 .\n",
      "\n",
      "\n",
      "Candidate: - Annotator\n",
      "Sentence: Our system, MACE (Multi-Annotator Competence Estimation), is available for download 1 .\n",
      "\n",
      "\n",
      "Candidate: Multi - Annotator Competence\n",
      "Sentence: Our system, MACE (Multi-Annotator Competence Estimation), is available for download 1 .\n",
      "\n",
      "\n",
      "Candidate: - Annotator Competence\n",
      "Sentence: Our system, MACE (Multi-Annotator Competence Estimation), is available for download 1 .\n",
      "\n",
      "\n",
      "Candidate: Annotator Competence\n",
      "Sentence: Our system, MACE (Multi-Annotator Competence Estimation), is available for download 1 .\n",
      "\n",
      "\n",
      "Candidate: Multi - Annotator Competence Estimation\n",
      "Sentence: Our system, MACE (Multi-Annotator Competence Estimation), is available for download 1 .\n",
      "\n",
      "\n",
      "Candidate: - Annotator Competence Estimation\n",
      "Sentence: Our system, MACE (Multi-Annotator Competence Estimation), is available for download 1 .\n",
      "\n",
      "\n",
      "Candidate: Annotator Competence Estimation\n",
      "Sentence: Our system, MACE (Multi-Annotator Competence Estimation), is available for download 1 .\n",
      "\n",
      "\n",
      "Candidate: Competence Estimation\n",
      "Sentence: Our system, MACE (Multi-Annotator Competence Estimation), is available for download 1 .\n",
      "\n",
      "\n",
      "Candidate: work concerns\n",
      "Sentence: This work concerns automatic topic segmentation of email conversations.\n",
      "\n",
      "Candidate: work concerns automatic topic\n",
      "Sentence: This work concerns automatic topic segmentation of email conversations.\n",
      "\n",
      "Candidate: concerns automatic topic\n",
      "Sentence: This work concerns automatic topic segmentation of email conversations.\n",
      "\n",
      "Candidate: automatic topic\n",
      "Sentence: This work concerns automatic topic segmentation of email conversations.\n",
      "\n",
      "Candidate: work concerns automatic topic segmentation\n",
      "Sentence: This work concerns automatic topic segmentation of email conversations.\n",
      "\n",
      "Candidate: concerns automatic topic segmentation\n",
      "Sentence: This work concerns automatic topic segmentation of email conversations.\n",
      "\n",
      "Candidate: automatic topic segmentation\n",
      "Sentence: This work concerns automatic topic segmentation of email conversations.\n",
      "\n",
      "Candidate: topic segmentation\n",
      "Sentence: This work concerns automatic topic segmentation of email conversations.\n",
      "\n",
      "Candidate: email conversations\n",
      "Sentence: This work concerns automatic topic segmentation of email conversations.\n",
      "\n",
      "Candidate: email threads\n",
      "Sentence: We present a corpus of email threads manually annotated with topics, and evaluate annotator reliability.\n",
      "\n",
      "Candidate: annotator reliability\n",
      "Sentence: We present a corpus of email threads manually annotated with topics, and evaluate annotator reliability.\n",
      "\n",
      "Candidate: first such email\n",
      "Sentence: To our knowledge, this is the first such email corpus.\n",
      "\n",
      "Candidate: such email\n",
      "Sentence: To our knowledge, this is the first such email corpus.\n",
      "\n",
      "Candidate: first such email corpus\n",
      "Sentence: To our knowledge, this is the first such email corpus.\n",
      "\n",
      "Candidate: such email corpus\n",
      "Sentence: To our knowledge, this is the first such email corpus.\n",
      "\n",
      "Candidate: email corpus\n",
      "Sentence: To our knowledge, this is the first such email corpus.\n",
      "\n",
      "Candidate: topic segmentation\n",
      "Sentence: We show how the existing topic segmentation models (i.e., Lexical Chain Segmenter (LCSeg) and Latent Dirichlet Allocation (LDA)) which are solely based on lexical information, can be applied to emails.\n",
      "\n",
      "Candidate: topic segmentation models\n",
      "Sentence: We show how the existing topic segmentation models (i.e., Lexical Chain Segmenter (LCSeg) and Latent Dirichlet Allocation (LDA)) which are solely based on lexical information, can be applied to emails.\n",
      "\n",
      "Candidate: segmentation models\n",
      "Sentence: We show how the existing topic segmentation models (i.e., Lexical Chain Segmenter (LCSeg) and Latent Dirichlet Allocation (LDA)) which are solely based on lexical information, can be applied to emails.\n",
      "\n",
      "Candidate: Lexical Chain\n",
      "Sentence: We show how the existing topic segmentation models (i.e., Lexical Chain Segmenter (LCSeg) and Latent Dirichlet Allocation (LDA)) which are solely based on lexical information, can be applied to emails.\n",
      "\n",
      "Candidate: Lexical Chain Segmenter\n",
      "Sentence: We show how the existing topic segmentation models (i.e., Lexical Chain Segmenter (LCSeg) and Latent Dirichlet Allocation (LDA)) which are solely based on lexical information, can be applied to emails.\n",
      "\n",
      "Candidate: Chain Segmenter\n",
      "Sentence: We show how the existing topic segmentation models (i.e., Lexical Chain Segmenter (LCSeg) and Latent Dirichlet Allocation (LDA)) which are solely based on lexical information, can be applied to emails.\n",
      "\n",
      "Candidate: Latent Dirichlet\n",
      "Sentence: We show how the existing topic segmentation models (i.e., Lexical Chain Segmenter (LCSeg) and Latent Dirichlet Allocation (LDA)) which are solely based on lexical information, can be applied to emails.\n",
      "\n",
      "Candidate: Latent Dirichlet Allocation\n",
      "Sentence: We show how the existing topic segmentation models (i.e., Lexical Chain Segmenter (LCSeg) and Latent Dirichlet Allocation (LDA)) which are solely based on lexical information, can be applied to emails.\n",
      "\n",
      "Candidate: Dirichlet Allocation\n",
      "Sentence: We show how the existing topic segmentation models (i.e., Lexical Chain Segmenter (LCSeg) and Latent Dirichlet Allocation (LDA)) which are solely based on lexical information, can be applied to emails.\n",
      "\n",
      "Candidate: lexical information\n",
      "Sentence: We show how the existing topic segmentation models (i.e., Lexical Chain Segmenter (LCSeg) and Latent Dirichlet Allocation (LDA)) which are solely based on lexical information, can be applied to emails.\n",
      "\n",
      "Candidate: novel extensions\n",
      "Sentence: By pointing out where these methods fail and what any desired model should consider, we propose two novel extensions of the models that not only use lexical information but also exploit finer level conversation structure in a principled way.\n",
      "\n",
      "Candidate: lexical information\n",
      "Sentence: By pointing out where these methods fail and what any desired model should consider, we propose two novel extensions of the models that not only use lexical information but also exploit finer level conversation structure in a principled way.\n",
      "\n",
      "Candidate: finer level\n",
      "Sentence: By pointing out where these methods fail and what any desired model should consider, we propose two novel extensions of the models that not only use lexical information but also exploit finer level conversation structure in a principled way.\n",
      "\n",
      "Candidate: finer level conversation\n",
      "Sentence: By pointing out where these methods fail and what any desired model should consider, we propose two novel extensions of the models that not only use lexical information but also exploit finer level conversation structure in a principled way.\n",
      "\n",
      "Candidate: level conversation\n",
      "Sentence: By pointing out where these methods fail and what any desired model should consider, we propose two novel extensions of the models that not only use lexical information but also exploit finer level conversation structure in a principled way.\n",
      "\n",
      "Candidate: finer level conversation structure\n",
      "Sentence: By pointing out where these methods fail and what any desired model should consider, we propose two novel extensions of the models that not only use lexical information but also exploit finer level conversation structure in a principled way.\n",
      "\n",
      "Candidate: level conversation structure\n",
      "Sentence: By pointing out where these methods fail and what any desired model should consider, we propose two novel extensions of the models that not only use lexical information but also exploit finer level conversation structure in a principled way.\n",
      "\n",
      "Candidate: conversation structure\n",
      "Sentence: By pointing out where these methods fail and what any desired model should consider, we propose two novel extensions of the models that not only use lexical information but also exploit finer level conversation structure in a principled way.\n",
      "\n",
      "Candidate: principled way\n",
      "Sentence: By pointing out where these methods fail and what any desired model should consider, we propose two novel extensions of the models that not only use lexical information but also exploit finer level conversation structure in a principled way.\n",
      "\n",
      "Candidate: Empirical evaluation\n",
      "Sentence: Empirical evaluation shows that LCSeg is a better model than LDA for segmenting an email thread into topical clusters and incorporating conversation structure into these models improves the performance significantly.\n",
      "\n",
      "\n",
      "Candidate: better model\n",
      "Sentence: Empirical evaluation shows that LCSeg is a better model than LDA for segmenting an email thread into topical clusters and incorporating conversation structure into these models improves the performance significantly.\n",
      "\n",
      "\n",
      "Candidate: email thread\n",
      "Sentence: Empirical evaluation shows that LCSeg is a better model than LDA for segmenting an email thread into topical clusters and incorporating conversation structure into these models improves the performance significantly.\n",
      "\n",
      "\n",
      "Candidate: topical clusters\n",
      "Sentence: Empirical evaluation shows that LCSeg is a better model than LDA for segmenting an email thread into topical clusters and incorporating conversation structure into these models improves the performance significantly.\n",
      "\n",
      "\n",
      "Candidate: conversation structure\n",
      "Sentence: Empirical evaluation shows that LCSeg is a better model than LDA for segmenting an email thread into topical clusters and incorporating conversation structure into these models improves the performance significantly.\n",
      "\n",
      "\n",
      "Candidate: semantic segmentation\n",
      "Sentence: Learning semantic segmentation models requires a huge amount of pixel-wise labeling.\n",
      "\n",
      "Candidate: semantic segmentation models\n",
      "Sentence: Learning semantic segmentation models requires a huge amount of pixel-wise labeling.\n",
      "\n",
      "Candidate: segmentation models\n",
      "Sentence: Learning semantic segmentation models requires a huge amount of pixel-wise labeling.\n",
      "\n",
      "Candidate: huge amount\n",
      "Sentence: Learning semantic segmentation models requires a huge amount of pixel-wise labeling.\n",
      "\n",
      "Candidate: wise labeling\n",
      "Sentence: Learning semantic segmentation models requires a huge amount of pixel-wise labeling.\n",
      "\n",
      "Candidate: target domain\n",
      "Sentence: However, labeled data may only be available abundantly in a domain different from the desired target domain, which only has minimal or no annotations.\n",
      "\n",
      "Candidate: novel framework\n",
      "Sentence: In this work, we propose a novel framework for domain adaptation in semantic segmentation with image-level weak labels in the target domain.\n",
      "\n",
      "Candidate: domain adaptation\n",
      "Sentence: In this work, we propose a novel framework for domain adaptation in semantic segmentation with image-level weak labels in the target domain.\n",
      "\n",
      "Candidate: semantic segmentation\n",
      "Sentence: In this work, we propose a novel framework for domain adaptation in semantic segmentation with image-level weak labels in the target domain.\n",
      "\n",
      "Candidate: level weak labels\n",
      "Sentence: In this work, we propose a novel framework for domain adaptation in semantic segmentation with image-level weak labels in the target domain.\n",
      "\n",
      "Candidate: weak labels\n",
      "Sentence: In this work, we propose a novel framework for domain adaptation in semantic segmentation with image-level weak labels in the target domain.\n",
      "\n",
      "Candidate: target domain\n",
      "Sentence: In this work, we propose a novel framework for domain adaptation in semantic segmentation with image-level weak labels in the target domain.\n",
      "\n",
      "Candidate: weak labels\n",
      "Sentence: The weak labels may be obtained based on a model prediction for unsupervised domain adaptation (UDA), or from a human annotator in a new weakly-supervised domain adaptation (WDA) paradigm for semantic segmentation.\n",
      "\n",
      "Candidate: model prediction\n",
      "Sentence: The weak labels may be obtained based on a model prediction for unsupervised domain adaptation (UDA), or from a human annotator in a new weakly-supervised domain adaptation (WDA) paradigm for semantic segmentation.\n",
      "\n",
      "Candidate: unsupervised domain\n",
      "Sentence: The weak labels may be obtained based on a model prediction for unsupervised domain adaptation (UDA), or from a human annotator in a new weakly-supervised domain adaptation (WDA) paradigm for semantic segmentation.\n",
      "\n",
      "Candidate: unsupervised domain adaptation\n",
      "Sentence: The weak labels may be obtained based on a model prediction for unsupervised domain adaptation (UDA), or from a human annotator in a new weakly-supervised domain adaptation (WDA) paradigm for semantic segmentation.\n",
      "\n",
      "Candidate: domain adaptation\n",
      "Sentence: The weak labels may be obtained based on a model prediction for unsupervised domain adaptation (UDA), or from a human annotator in a new weakly-supervised domain adaptation (WDA) paradigm for semantic segmentation.\n",
      "\n",
      "Candidate: human annotator\n",
      "Sentence: The weak labels may be obtained based on a model prediction for unsupervised domain adaptation (UDA), or from a human annotator in a new weakly-supervised domain adaptation (WDA) paradigm for semantic segmentation.\n",
      "\n",
      "Candidate: domain adaptation\n",
      "Sentence: The weak labels may be obtained based on a model prediction for unsupervised domain adaptation (UDA), or from a human annotator in a new weakly-supervised domain adaptation (WDA) paradigm for semantic segmentation.\n",
      "\n",
      "Candidate: semantic segmentation\n",
      "Sentence: The weak labels may be obtained based on a model prediction for unsupervised domain adaptation (UDA), or from a human annotator in a new weakly-supervised domain adaptation (WDA) paradigm for semantic segmentation.\n",
      "\n",
      "Candidate: weak labels\n",
      "Sentence: Using weak labels is both practical and useful, since (i) collecting image-level target annotations is comparably cheap in WDA and incurs no cost in UDA, and (ii) it opens the opportunity for category-wise domain alignment.\n",
      "\n",
      "Candidate: level target\n",
      "Sentence: Using weak labels is both practical and useful, since (i) collecting image-level target annotations is comparably cheap in WDA and incurs no cost in UDA, and (ii) it opens the opportunity for category-wise domain alignment.\n",
      "\n",
      "Candidate: level target annotations\n",
      "Sentence: Using weak labels is both practical and useful, since (i) collecting image-level target annotations is comparably cheap in WDA and incurs no cost in UDA, and (ii) it opens the opportunity for category-wise domain alignment.\n",
      "\n",
      "Candidate: target annotations\n",
      "Sentence: Using weak labels is both practical and useful, since (i) collecting image-level target annotations is comparably cheap in WDA and incurs no cost in UDA, and (ii) it opens the opportunity for category-wise domain alignment.\n",
      "\n",
      "Candidate: wise domain\n",
      "Sentence: Using weak labels is both practical and useful, since (i) collecting image-level target annotations is comparably cheap in WDA and incurs no cost in UDA, and (ii) it opens the opportunity for category-wise domain alignment.\n",
      "\n",
      "Candidate: wise domain alignment\n",
      "Sentence: Using weak labels is both practical and useful, since (i) collecting image-level target annotations is comparably cheap in WDA and incurs no cost in UDA, and (ii) it opens the opportunity for category-wise domain alignment.\n",
      "\n",
      "Candidate: domain alignment\n",
      "Sentence: Using weak labels is both practical and useful, since (i) collecting image-level target annotations is comparably cheap in WDA and incurs no cost in UDA, and (ii) it opens the opportunity for category-wise domain alignment.\n",
      "\n",
      "Candidate: weak labels\n",
      "Sentence: Our framework uses weak labels to enable the interplay between feature alignment and pseudo-labeling, improving both in the process of domain adaptation.\n",
      "\n",
      "Candidate: feature alignment\n",
      "Sentence: Our framework uses weak labels to enable the interplay between feature alignment and pseudo-labeling, improving both in the process of domain adaptation.\n",
      "\n",
      "Candidate: pseudo -\n",
      "Sentence: Our framework uses weak labels to enable the interplay between feature alignment and pseudo-labeling, improving both in the process of domain adaptation.\n",
      "\n",
      "Candidate: domain adaptation\n",
      "Sentence: Our framework uses weak labels to enable the interplay between feature alignment and pseudo-labeling, improving both in the process of domain adaptation.\n",
      "\n",
      "Candidate: label classification\n",
      "Sentence: Specifically, we develop a weak-label classification module to enforce the network to attend to certain categories, and then use such training signals to guide the proposed category-wise alignment method.\n",
      "\n",
      "Candidate: label classification module\n",
      "Sentence: Specifically, we develop a weak-label classification module to enforce the network to attend to certain categories, and then use such training signals to guide the proposed category-wise alignment method.\n",
      "\n",
      "Candidate: classification module\n",
      "Sentence: Specifically, we develop a weak-label classification module to enforce the network to attend to certain categories, and then use such training signals to guide the proposed category-wise alignment method.\n",
      "\n",
      "Candidate: certain categories\n",
      "Sentence: Specifically, we develop a weak-label classification module to enforce the network to attend to certain categories, and then use such training signals to guide the proposed category-wise alignment method.\n",
      "\n",
      "Candidate: such training\n",
      "Sentence: Specifically, we develop a weak-label classification module to enforce the network to attend to certain categories, and then use such training signals to guide the proposed category-wise alignment method.\n",
      "\n",
      "Candidate: such training signals\n",
      "Sentence: Specifically, we develop a weak-label classification module to enforce the network to attend to certain categories, and then use such training signals to guide the proposed category-wise alignment method.\n",
      "\n",
      "Candidate: training signals\n",
      "Sentence: Specifically, we develop a weak-label classification module to enforce the network to attend to certain categories, and then use such training signals to guide the proposed category-wise alignment method.\n",
      "\n",
      "Candidate: wise alignment\n",
      "Sentence: Specifically, we develop a weak-label classification module to enforce the network to attend to certain categories, and then use such training signals to guide the proposed category-wise alignment method.\n",
      "\n",
      "Candidate: wise alignment method\n",
      "Sentence: Specifically, we develop a weak-label classification module to enforce the network to attend to certain categories, and then use such training signals to guide the proposed category-wise alignment method.\n",
      "\n",
      "Candidate: alignment method\n",
      "Sentence: Specifically, we develop a weak-label classification module to enforce the network to attend to certain categories, and then use such training signals to guide the proposed category-wise alignment method.\n",
      "\n",
      "Candidate: considerable improvements\n",
      "Sentence: In experiments, we show considerable improvements with respect to the existing state-of-the-arts in UDA and present a new benchmark in the WDA setting.\n",
      "\n",
      "Candidate: new benchmark\n",
      "Sentence: In experiments, we show considerable improvements with respect to the existing state-of-the-arts in UDA and present a new benchmark in the WDA setting.\n",
      "\n",
      "Candidate: WDA setting\n",
      "Sentence: In experiments, we show considerable improvements with respect to the existing state-of-the-arts in UDA and present a new benchmark in the WDA setting.\n",
      "\n",
      "Candidate: Project page\n",
      "Sentence: Project page is at this http URL.\n",
      "\n",
      "\n",
      "Candidate: http URL\n",
      "Sentence: Project page is at this http URL.\n",
      "\n",
      "\n",
      "Candidate: TIS prediction\n",
      "Sentence: SUMMARY We proposed a tool named MetaTISA with an aim to improve TIS prediction of current gene-finders for metagenomes.\n",
      "\n",
      "Candidate: current gene\n",
      "Sentence: SUMMARY We proposed a tool named MetaTISA with an aim to improve TIS prediction of current gene-finders for metagenomes.\n",
      "\n",
      "Candidate: step strategy\n",
      "Sentence: The method employs a two-step strategy to predict translation initiation sites (TISs) by first clustering metagenomic fragments into phylogenetic groups and then predicting TISs independently for each group in an unsupervised manner.\n",
      "\n",
      "Candidate: translation initiation\n",
      "Sentence: The method employs a two-step strategy to predict translation initiation sites (TISs) by first clustering metagenomic fragments into phylogenetic groups and then predicting TISs independently for each group in an unsupervised manner.\n",
      "\n",
      "Candidate: translation initiation sites\n",
      "Sentence: The method employs a two-step strategy to predict translation initiation sites (TISs) by first clustering metagenomic fragments into phylogenetic groups and then predicting TISs independently for each group in an unsupervised manner.\n",
      "\n",
      "Candidate: initiation sites\n",
      "Sentence: The method employs a two-step strategy to predict translation initiation sites (TISs) by first clustering metagenomic fragments into phylogenetic groups and then predicting TISs independently for each group in an unsupervised manner.\n",
      "\n",
      "Candidate: first clustering metagenomic fragments\n",
      "Sentence: The method employs a two-step strategy to predict translation initiation sites (TISs) by first clustering metagenomic fragments into phylogenetic groups and then predicting TISs independently for each group in an unsupervised manner.\n",
      "\n",
      "Candidate: clustering metagenomic fragments\n",
      "Sentence: The method employs a two-step strategy to predict translation initiation sites (TISs) by first clustering metagenomic fragments into phylogenetic groups and then predicting TISs independently for each group in an unsupervised manner.\n",
      "\n",
      "Candidate: metagenomic fragments\n",
      "Sentence: The method employs a two-step strategy to predict translation initiation sites (TISs) by first clustering metagenomic fragments into phylogenetic groups and then predicting TISs independently for each group in an unsupervised manner.\n",
      "\n",
      "Candidate: phylogenetic groups\n",
      "Sentence: The method employs a two-step strategy to predict translation initiation sites (TISs) by first clustering metagenomic fragments into phylogenetic groups and then predicting TISs independently for each group in an unsupervised manner.\n",
      "\n",
      "Candidate: unsupervised manner\n",
      "Sentence: The method employs a two-step strategy to predict translation initiation sites (TISs) by first clustering metagenomic fragments into phylogenetic groups and then predicting TISs independently for each group in an unsupervised manner.\n",
      "\n",
      "Candidate: TIS prediction\n",
      "Sentence: As evaluated on experimentally verified TISs, MetaTISA greatly improves the accuracies of TIS prediction of current gene-finders.\n",
      "\n",
      "Candidate: current gene\n",
      "Sentence: As evaluated on experimentally verified TISs, MetaTISA greatly improves the accuracies of TIS prediction of current gene-finders.\n",
      "\n",
      "Candidate: C++ source\n",
      "Sentence: AVAILABILITY The C++ source code is freely available under the GNU GPL license via http://mech.ctb.pku.edu.cn/MetaTISA/.\n",
      "\n",
      "Candidate: C++ source code\n",
      "Sentence: AVAILABILITY The C++ source code is freely available under the GNU GPL license via http://mech.ctb.pku.edu.cn/MetaTISA/.\n",
      "\n",
      "Candidate: source code\n",
      "Sentence: AVAILABILITY The C++ source code is freely available under the GNU GPL license via http://mech.ctb.pku.edu.cn/MetaTISA/.\n",
      "\n",
      "Candidate: GNU GPL\n",
      "Sentence: AVAILABILITY The C++ source code is freely available under the GNU GPL license via http://mech.ctb.pku.edu.cn/MetaTISA/.\n",
      "\n",
      "Candidate: GNU GPL license\n",
      "Sentence: AVAILABILITY The C++ source code is freely available under the GNU GPL license via http://mech.ctb.pku.edu.cn/MetaTISA/.\n",
      "\n",
      "Candidate: GPL license\n",
      "Sentence: AVAILABILITY The C++ source code is freely available under the GNU GPL license via http://mech.ctb.pku.edu.cn/MetaTISA/.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import namedtuple\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a namedtuple for candidates\n",
    "Candidate = namedtuple(\"Candidate\", [\"phrase\", \"sentence\"])\n",
    "\n",
    "# Custom rule for multiword expression candidates\n",
    "def extract_multiword_candidates_with_sentences_any_order(doc):\n",
    "    candidates_prases = []\n",
    "    candidate_words = []\n",
    "    current_sentence = \"\"\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        current_sentence = sent.text\n",
    "        current_candidate = []\n",
    "        for token in sent:\n",
    "            if token.pos_ in [\"ADJ\", \"NOUN\", \"PROPN\"]:\n",
    "                current_candidate.append(token.text)\n",
    "            else:\n",
    "                if len(current_candidate)>1:\n",
    "                    candidates_prases.append(Candidate(\" \".join(current_candidate), current_sentence))\n",
    "                elif len(current_candidate)==1:\n",
    "                    candidate_words.append(Candidate(\" \".join(current_candidate), current_sentence))\n",
    "                current_candidate = []\n",
    "        if len(current_candidate)>1:\n",
    "            candidates_prases.append(Candidate(\" \".join(current_candidate), current_sentence))\n",
    "        elif len(current_candidate)==1:\n",
    "            candidate_words.append(Candidate(\" \".join(current_candidate), current_sentence))\n",
    "        \n",
    "\n",
    "    return candidates_prases, candidate_words\n",
    "\n",
    "\n",
    "def extract_multiword_candidates_with_sentences_any_order_allsub(doc):\n",
    "    candidate_phrases = []\n",
    "    candidate_words=[]\n",
    "    current_sentence = \"\"\n",
    "    for sent in doc.sents:\n",
    "        current_sentence = sent.text\n",
    "        current_candidate = []\n",
    "        for token in sent:\n",
    "            if token.pos_ in [\"ADJ\", \"NOUN\", \"PROPN\"]:\n",
    "                current_candidate.append(token.text)\n",
    "            if len(current_candidate)>1:\n",
    "                    candidate_phrases.append(Candidate(\" \".join(current_candidate), current_sentence))\n",
    "            elif len(current_candidate)==1:\n",
    "                candidate_words.append(Candidate(\" \".join(current_candidate), current_sentence))\n",
    "            if token.pos_ not in [\"ADJ\", \"NOUN\", \"PROPN\"]:\n",
    "                current_candidate = []\n",
    "        if len(current_candidate)>1:\n",
    "            candidate_phrases.append(Candidate(\" \".join(current_candidate), current_sentence))\n",
    "        elif len(current_candidate)==1:\n",
    "            candidate_words.append(Candidate(\" \".join(current_candidate), current_sentence))\n",
    "            \n",
    "\n",
    "    return candidate_phrases, candidate_words\n",
    "\n",
    "def extract_multiword_candidates_with_sentences_order_allsub(doc):\n",
    "    candidate_phrases = []\n",
    "    candidate_words=[]\n",
    "    current_sentence = \"\"\n",
    "    for sent in doc.sents:\n",
    "        current_sentence = sent.text\n",
    "        current_candidate = []\n",
    "        noun_met=False\n",
    "        for token in sent:\n",
    "            if token.pos_ in [\"ADJ\"]:\n",
    "                current_candidate.append(token.text)\n",
    "            elif token.pos_ in [ \"NOUN\", \"PROPN\"]:\n",
    "                noun_met=True\n",
    "                current_candidate.append(token.text)\n",
    "                for i in range(len(current_candidate)-1):\n",
    "                    candidate_phrases.append(Candidate(\" \".join(current_candidate[i:]), current_sentence))\n",
    "            else:\n",
    "                if len(current_candidate)==1 and noun_met:\n",
    "                    candidate_words.append(current_candidate)\n",
    "                current_candidate = []\n",
    "                noun_met=False\n",
    "        if len(current_candidate)==1 and noun_met:\n",
    "            candidate_words.append(current_candidate)\n",
    "    return candidate_phrases, candidate_words\n",
    "def extract_multiword_candidates_with_sentences_order(doc):\n",
    "    candidates = []\n",
    "    current_sentence = \"\"\n",
    "    for sent in doc.sents:\n",
    "        current_sentence = sent.text\n",
    "        current_candidate = []\n",
    "        noun_met=False\n",
    "        for token in sent:\n",
    "            if token.pos_ in [\"ADJ\"]:\n",
    "                current_candidate.append(token.text)\n",
    "            elif token.pos_ in [ \"NOUN\", \"PROPN\"]:\n",
    "                noun_met=True\n",
    "                current_candidate.append(token.text)\n",
    "                candidates.append(Candidate(\" \".join(current_candidate), current_sentence))\n",
    "            else:\n",
    "                \n",
    "                current_candidate = []\n",
    "\n",
    "    return candidates\n",
    "file= open('abstracts.txt', 'r')\n",
    "# Example text\n",
    "text = file.read()\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract multiword expression candidates with corresponding sentences\n",
    "candidate_phrases, candidate_words = extract_multiword_candidates_with_sentences_order_allsub(doc)\n",
    "\n",
    "# Print the candidates with sentences\n",
    "for candidate in candidate_phrases:\n",
    "    print(\"Candidate:\", candidate.phrase)\n",
    "    print(\"Sentence:\", candidate.sentence)\n",
    "    print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T07:43:39.461525Z",
     "start_time": "2023-09-07T07:43:38.520884100Z"
    }
   },
   "id": "bc8f1f3c98c7c136"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "['Collecting sentence-transformers',\n '  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)',\n '     ---------------------------------------- 0.0/86.0 kB ? eta -:--:--',\n '     ------------- ------------------------ 30.7/86.0 kB 660.6 kB/s eta 0:00:01',\n '     ------------------ ------------------- 41.0/86.0 kB 393.8 kB/s eta 0:00:01',\n '     -------------------------------------- 86.0/86.0 kB 605.7 kB/s eta 0:00:00',\n '  Preparing metadata (setup.py): started',\n \"  Preparing metadata (setup.py): finished with status 'done'\",\n 'Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)',\n '  Obtaining dependency information for transformers<5.0.0,>=4.6.0 from https://files.pythonhosted.org/packages/e1/9d/4d9fe5c3b820db10773392ac5f4a0c8dab668f70b245ce2ce09785166128/transformers-4.33.0-py3-none-any.whl.metadata',\n '  Downloading transformers-4.33.0-py3-none-any.whl.metadata (119 kB)',\n '     ---------------------------------------- 0.0/119.9 kB ? eta -:--:--',\n '     -------------------------------------- 119.9/119.9 kB 2.3 MB/s eta 0:00:00',\n 'Requirement already satisfied: tqdm in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from sentence-transformers) (4.66.1)',\n 'Collecting torch>=1.6.0 (from sentence-transformers)',\n '  Using cached torch-2.0.1-cp311-cp311-win_amd64.whl (172.3 MB)',\n 'Collecting torchvision (from sentence-transformers)',\n '  Downloading torchvision-0.15.2-cp311-cp311-win_amd64.whl (1.2 MB)',\n '     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--',\n '     ------- -------------------------------- 0.2/1.2 MB 6.9 MB/s eta 0:00:01',\n '     -------- ------------------------------- 0.3/1.2 MB 3.2 MB/s eta 0:00:01',\n '     ---------------- ----------------------- 0.5/1.2 MB 4.4 MB/s eta 0:00:01',\n '     ------------------- -------------------- 0.6/1.2 MB 3.4 MB/s eta 0:00:01',\n '     ------------------------------- -------- 0.9/1.2 MB 4.3 MB/s eta 0:00:01',\n '     -------------------------------------- - 1.2/1.2 MB 4.3 MB/s eta 0:00:01',\n '     ---------------------------------------- 1.2/1.2 MB 4.2 MB/s eta 0:00:00',\n 'Requirement already satisfied: numpy in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from sentence-transformers) (1.25.2)',\n 'Collecting scikit-learn (from sentence-transformers)',\n '  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/77/85/bff3a1e818ec6aa3dd466ff4f4b0a727db9fdb41f2e849747ad902ddbe95/scikit_learn-1.3.0-cp311-cp311-win_amd64.whl.metadata',\n '  Downloading scikit_learn-1.3.0-cp311-cp311-win_amd64.whl.metadata (11 kB)',\n 'Collecting scipy (from sentence-transformers)',\n '  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/06/15/e73734f9170b66c6a84a0bd7e03586e87e77404e2eb8e34749fc49fa43f7/scipy-1.11.2-cp311-cp311-win_amd64.whl.metadata',\n '  Downloading scipy-1.11.2-cp311-cp311-win_amd64.whl.metadata (59 kB)',\n '     ---------------------------------------- 0.0/59.1 kB ? eta -:--:--',\n '     ---------------------------------------- 59.1/59.1 kB ? eta 0:00:00',\n 'Collecting nltk (from sentence-transformers)',\n '  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)',\n '     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--',\n '     --- ------------------------------------ 0.1/1.5 MB 8.3 MB/s eta 0:00:01',\n '     ---- ----------------------------------- 0.2/1.5 MB 10.2 MB/s eta 0:00:01',\n '     ---- ----------------------------------- 0.2/1.5 MB 10.2 MB/s eta 0:00:01',\n '     -------------- ------------------------- 0.5/1.5 MB 3.7 MB/s eta 0:00:01',\n '     --------------------- ------------------ 0.8/1.5 MB 3.9 MB/s eta 0:00:01',\n '     ------------------------------------- -- 1.4/1.5 MB 5.7 MB/s eta 0:00:01',\n '     ---------------------------------------- 1.5/1.5 MB 5.3 MB/s eta 0:00:00',\n 'Collecting sentencepiece (from sentence-transformers)',\n '  Downloading sentencepiece-0.1.99-cp311-cp311-win_amd64.whl (977 kB)',\n '     ---------------------------------------- 0.0/977.5 kB ? eta -:--:--',\n '     ----------------- -------------------- 440.3/977.5 kB 9.2 MB/s eta 0:00:01',\n '     ---------------------------- --------- 727.0/977.5 kB 7.6 MB/s eta 0:00:01',\n '     -------------------------------------- 977.5/977.5 kB 7.7 MB/s eta 0:00:00',\n 'Collecting huggingface-hub>=0.4.0 (from sentence-transformers)',\n '  Obtaining dependency information for huggingface-hub>=0.4.0 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata',\n '  Using cached huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)',\n 'Collecting filelock (from huggingface-hub>=0.4.0->sentence-transformers)',\n '  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/52/90/45223db4e1df30ff14e8aebf9a1bf0222da2e7b49e53692c968f36817812/filelock-3.12.3-py3-none-any.whl.metadata',\n '  Downloading filelock-3.12.3-py3-none-any.whl.metadata (2.7 kB)',\n 'Collecting fsspec (from huggingface-hub>=0.4.0->sentence-transformers)',\n '  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/3a/9f/b40e8e5be886143379000af5fc0c675352d59e82fd869d24bf784161dc77/fsspec-2023.9.0-py3-none-any.whl.metadata',\n '  Downloading fsspec-2023.9.0-py3-none-any.whl.metadata (6.7 kB)',\n 'Requirement already satisfied: requests in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)',\n 'Requirement already satisfied: pyyaml>=5.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)',\n 'Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)',\n 'Requirement already satisfied: packaging>=20.9 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)',\n 'Collecting sympy (from torch>=1.6.0->sentence-transformers)',\n '  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)',\n 'Collecting networkx (from torch>=1.6.0->sentence-transformers)',\n '  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)',\n 'Requirement already satisfied: jinja2 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)',\n 'Requirement already satisfied: colorama in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from tqdm->sentence-transformers) (0.4.6)',\n 'Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.6.0->sentence-transformers)',\n '  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/de/cd/d80c9e284ae6c1b2172dacf0651d25b78ee1f7efbc12d74ea7b87c766263/regex-2023.8.8-cp311-cp311-win_amd64.whl.metadata',\n '  Using cached regex-2023.8.8-cp311-cp311-win_amd64.whl.metadata (42 kB)',\n 'Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)',\n '  Using cached tokenizers-0.13.3-cp311-cp311-win_amd64.whl (3.5 MB)',\n 'Collecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)',\n '  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/f3/c9/6f14c11265ecc9ff06fddae423eee40061c3841a1e44ca1e7b1bb8ce3b48/safetensors-0.3.3-cp311-cp311-win_amd64.whl.metadata',\n '  Downloading safetensors-0.3.3-cp311-cp311-win_amd64.whl.metadata (4.8 kB)',\n 'Requirement already satisfied: click in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from nltk->sentence-transformers) (8.1.7)',\n 'Collecting joblib (from nltk->sentence-transformers)',\n '  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata',\n '  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)',\n 'Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers)',\n '  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata',\n '  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)',\n 'Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->sentence-transformers)',\n '  Obtaining dependency information for pillow!=8.3.*,>=5.3.0 from https://files.pythonhosted.org/packages/66/d4/054e491f0880bf0119ee79cdc03264e01d5732e06c454da8c69b83a7c8f2/Pillow-10.0.0-cp311-cp311-win_amd64.whl.metadata',\n '  Downloading Pillow-10.0.0-cp311-cp311-win_amd64.whl.metadata (9.6 kB)',\n 'Requirement already satisfied: MarkupSafe>=2.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)',\n 'Requirement already satisfied: charset-normalizer<4,>=2 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)',\n 'Requirement already satisfied: idna<4,>=2.5 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)',\n 'Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)',\n 'Requirement already satisfied: certifi>=2017.4.17 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)',\n 'Collecting mpmath>=0.19 (from sympy->torch>=1.6.0->sentence-transformers)',\n '  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)',\n 'Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)',\n 'Downloading transformers-4.33.0-py3-none-any.whl (7.6 MB)',\n '   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--',\n '   - -------------------------------------- 0.4/7.6 MB 7.6 MB/s eta 0:00:01',\n '   ---- ----------------------------------- 0.8/7.6 MB 8.2 MB/s eta 0:00:01',\n '   ----- ---------------------------------- 1.1/7.6 MB 7.9 MB/s eta 0:00:01',\n '   -------- ------------------------------- 1.5/7.6 MB 8.9 MB/s eta 0:00:01',\n '   -------- ------------------------------- 1.5/7.6 MB 8.9 MB/s eta 0:00:01',\n '   --------- ------------------------------ 1.9/7.6 MB 6.6 MB/s eta 0:00:01',\n '   ----------- ---------------------------- 2.3/7.6 MB 6.9 MB/s eta 0:00:01',\n '   -------------- ------------------------- 2.7/7.6 MB 7.3 MB/s eta 0:00:01',\n '   ---------------- ----------------------- 3.2/7.6 MB 7.4 MB/s eta 0:00:01',\n '   ------------------ --------------------- 3.6/7.6 MB 7.6 MB/s eta 0:00:01',\n '   --------------------- ------------------ 4.0/7.6 MB 7.8 MB/s eta 0:00:01',\n '   ----------------------- ---------------- 4.5/7.6 MB 7.9 MB/s eta 0:00:01',\n '   -------------------------- ------------- 5.0/7.6 MB 8.2 MB/s eta 0:00:01',\n '   ---------------------------- ----------- 5.5/7.6 MB 8.3 MB/s eta 0:00:01',\n '   ------------------------------ --------- 5.9/7.6 MB 8.4 MB/s eta 0:00:01',\n '   -------------------------------- ------- 6.2/7.6 MB 8.3 MB/s eta 0:00:01',\n '   ----------------------------------- ---- 6.7/7.6 MB 8.4 MB/s eta 0:00:01',\n '   ------------------------------------ --- 7.0/7.6 MB 8.4 MB/s eta 0:00:01',\n '   ------------------------------------ --- 7.0/7.6 MB 8.4 MB/s eta 0:00:01',\n '   ---------------------------------------  7.6/7.6 MB 8.1 MB/s eta 0:00:01',\n '   ---------------------------------------- 7.6/7.6 MB 8.0 MB/s eta 0:00:00',\n 'Downloading scikit_learn-1.3.0-cp311-cp311-win_amd64.whl (9.2 MB)',\n '   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--',\n '   - -------------------------------------- 0.4/9.2 MB 8.5 MB/s eta 0:00:02',\n '   --- ------------------------------------ 0.8/9.2 MB 8.4 MB/s eta 0:00:02',\n '   ----- ---------------------------------- 1.2/9.2 MB 8.5 MB/s eta 0:00:01',\n '   ------ --------------------------------- 1.6/9.2 MB 8.5 MB/s eta 0:00:01',\n '   -------- ------------------------------- 2.0/9.2 MB 8.4 MB/s eta 0:00:01',\n '   ---------- ----------------------------- 2.4/9.2 MB 8.9 MB/s eta 0:00:01',\n '   ----------- ---------------------------- 2.8/9.2 MB 8.4 MB/s eta 0:00:01',\n '   ------------- -------------------------- 3.2/9.2 MB 8.5 MB/s eta 0:00:01',\n '   --------------- ------------------------ 3.5/9.2 MB 8.3 MB/s eta 0:00:01',\n '   ----------------- ---------------------- 4.0/9.2 MB 8.4 MB/s eta 0:00:01',\n '   ------------------ --------------------- 4.1/9.2 MB 8.0 MB/s eta 0:00:01',\n '   -------------------- ------------------- 4.6/9.2 MB 8.2 MB/s eta 0:00:01',\n '   --------------------- ------------------ 4.9/9.2 MB 8.3 MB/s eta 0:00:01',\n '   ----------------------- ---------------- 5.4/9.2 MB 8.2 MB/s eta 0:00:01',\n '   ------------------------ --------------- 5.7/9.2 MB 8.1 MB/s eta 0:00:01',\n '   -------------------------- ------------- 6.1/9.2 MB 8.1 MB/s eta 0:00:01',\n '   ---------------------------- ----------- 6.6/9.2 MB 8.3 MB/s eta 0:00:01',\n '   ----------------------------- ---------- 6.9/9.2 MB 8.1 MB/s eta 0:00:01',\n '   ------------------------------- -------- 7.4/9.2 MB 8.2 MB/s eta 0:00:01',\n '   -------------------------------- ------- 7.6/9.2 MB 8.2 MB/s eta 0:00:01',\n '   --------------------------------- ------ 7.6/9.2 MB 7.7 MB/s eta 0:00:01',\n '   ---------------------------------- ----- 8.0/9.2 MB 7.7 MB/s eta 0:00:01',\n '   ------------------------------------ --- 8.4/9.2 MB 7.8 MB/s eta 0:00:01',\n '   -------------------------------------- - 8.7/9.2 MB 7.8 MB/s eta 0:00:01',\n '   ---------------------------------------  9.2/9.2 MB 7.8 MB/s eta 0:00:01',\n '   ---------------------------------------- 9.2/9.2 MB 7.6 MB/s eta 0:00:00',\n 'Downloading scipy-1.11.2-cp311-cp311-win_amd64.whl (44.0 MB)',\n '   ---------------------------------------- 0.0/44.0 MB ? eta -:--:--',\n '   ---------------------------------------- 0.4/44.0 MB 8.5 MB/s eta 0:00:06',\n '    --------------------------------------- 0.7/44.0 MB 7.7 MB/s eta 0:00:06',\n '   - -------------------------------------- 1.2/44.0 MB 8.2 MB/s eta 0:00:06',\n '   - -------------------------------------- 1.6/44.0 MB 8.5 MB/s eta 0:00:05',\n '   - -------------------------------------- 1.8/44.0 MB 8.3 MB/s eta 0:00:06',\n '   -- ------------------------------------- 2.3/44.0 MB 8.1 MB/s eta 0:00:06',\n '   -- ------------------------------------- 2.7/44.0 MB 8.1 MB/s eta 0:00:06',\n '   -- ------------------------------------- 3.0/44.0 MB 8.1 MB/s eta 0:00:06',\n '   --- ------------------------------------ 3.4/44.0 MB 8.0 MB/s eta 0:00:06',\n '   --- ------------------------------------ 3.7/44.0 MB 7.9 MB/s eta 0:00:06',\n '   --- ------------------------------------ 4.0/44.0 MB 7.8 MB/s eta 0:00:06',\n '   ---- ----------------------------------- 4.5/44.0 MB 8.0 MB/s eta 0:00:05',\n '   ---- ----------------------------------- 4.9/44.0 MB 8.1 MB/s eta 0:00:05',\n '   ---- ----------------------------------- 5.2/44.0 MB 7.9 MB/s eta 0:00:05',\n '   ----- ---------------------------------- 5.6/44.0 MB 8.0 MB/s eta 0:00:05',\n '   ----- ---------------------------------- 6.0/44.0 MB 8.0 MB/s eta 0:00:05',\n '   ----- ---------------------------------- 6.2/44.0 MB 7.8 MB/s eta 0:00:05',\n '   ------ --------------------------------- 6.7/44.0 MB 7.9 MB/s eta 0:00:05',\n '   ------ --------------------------------- 7.1/44.0 MB 8.0 MB/s eta 0:00:05',\n '   ------ --------------------------------- 7.5/44.0 MB 8.0 MB/s eta 0:00:05',\n '   ------- -------------------------------- 7.9/44.0 MB 8.0 MB/s eta 0:00:05',\n '   ------- -------------------------------- 8.1/44.0 MB 7.9 MB/s eta 0:00:05',\n '   ------- -------------------------------- 8.2/44.0 MB 7.6 MB/s eta 0:00:05',\n '   ------- -------------------------------- 8.6/44.0 MB 7.6 MB/s eta 0:00:05',\n '   -------- ------------------------------- 9.0/44.0 MB 7.7 MB/s eta 0:00:05',\n '   -------- ------------------------------- 9.5/44.0 MB 7.7 MB/s eta 0:00:05',\n '   -------- ------------------------------- 9.9/44.0 MB 7.8 MB/s eta 0:00:05',\n '   --------- ------------------------------ 10.2/44.0 MB 7.8 MB/s eta 0:00:05',\n '   --------- ------------------------------ 10.6/44.0 MB 7.8 MB/s eta 0:00:05',\n '   --------- ------------------------------ 10.9/44.0 MB 7.7 MB/s eta 0:00:05',\n '   ---------- ----------------------------- 11.3/44.0 MB 7.8 MB/s eta 0:00:05',\n '   ---------- ----------------------------- 11.7/44.0 MB 7.7 MB/s eta 0:00:05',\n '   ----------- ---------------------------- 12.2/44.0 MB 7.9 MB/s eta 0:00:05',\n '   ----------- ---------------------------- 12.6/44.0 MB 7.9 MB/s eta 0:00:04',\n '   ----------- ---------------------------- 13.1/44.0 MB 8.0 MB/s eta 0:00:04',\n '   ------------ --------------------------- 13.5/44.0 MB 8.0 MB/s eta 0:00:04',\n '   ------------ --------------------------- 14.0/44.0 MB 8.2 MB/s eta 0:00:04',\n '   ------------- -------------------------- 14.4/44.0 MB 8.2 MB/s eta 0:00:04',\n '   ------------- -------------------------- 14.8/44.0 MB 8.2 MB/s eta 0:00:04',\n '   ------------- -------------------------- 15.3/44.0 MB 8.2 MB/s eta 0:00:04',\n '   -------------- ------------------------- 15.7/44.0 MB 8.3 MB/s eta 0:00:04',\n '   -------------- ------------------------- 16.1/44.0 MB 8.3 MB/s eta 0:00:04',\n '   -------------- ------------------------- 16.5/44.0 MB 8.4 MB/s eta 0:00:04',\n '   --------------- ------------------------ 16.9/44.0 MB 8.4 MB/s eta 0:00:04',\n '   --------------- ------------------------ 17.2/44.0 MB 8.5 MB/s eta 0:00:04',\n '   ---------------- ----------------------- 17.7/44.0 MB 8.4 MB/s eta 0:00:04',\n '   ---------------- ----------------------- 18.1/44.0 MB 8.4 MB/s eta 0:00:04',\n '   ---------------- ----------------------- 18.5/44.0 MB 9.0 MB/s eta 0:00:03',\n '   ----------------- ---------------------- 18.9/44.0 MB 8.8 MB/s eta 0:00:03',\n '   ----------------- ---------------------- 19.4/44.0 MB 8.8 MB/s eta 0:00:03',\n '   ----------------- ---------------------- 19.8/44.0 MB 8.8 MB/s eta 0:00:03',\n '   ------------------ --------------------- 20.2/44.0 MB 8.8 MB/s eta 0:00:03',\n '   ------------------ --------------------- 20.6/44.0 MB 8.8 MB/s eta 0:00:03',\n '   ------------------- -------------------- 21.0/44.0 MB 9.0 MB/s eta 0:00:03',\n '   ------------------- -------------------- 21.4/44.0 MB 9.0 MB/s eta 0:00:03',\n '   ------------------- -------------------- 21.8/44.0 MB 9.0 MB/s eta 0:00:03',\n '   -------------------- ------------------- 22.2/44.0 MB 9.0 MB/s eta 0:00:03',\n '   -------------------- ------------------- 22.6/44.0 MB 8.8 MB/s eta 0:00:03',\n '   --------------------- ------------------ 23.1/44.0 MB 9.0 MB/s eta 0:00:03',\n '   --------------------- ------------------ 23.5/44.0 MB 9.0 MB/s eta 0:00:03',\n '   --------------------- ------------------ 23.8/44.0 MB 8.7 MB/s eta 0:00:03',\n '   --------------------- ------------------ 24.1/44.0 MB 8.6 MB/s eta 0:00:03',\n '   ---------------------- ----------------- 24.6/44.0 MB 8.7 MB/s eta 0:00:03',\n '   ---------------------- ----------------- 24.9/44.0 MB 8.6 MB/s eta 0:00:03',\n '   ----------------------- ---------------- 25.4/44.0 MB 8.6 MB/s eta 0:00:03',\n '   ----------------------- ---------------- 25.7/44.0 MB 8.6 MB/s eta 0:00:03',\n '   ----------------------- ---------------- 26.2/44.0 MB 8.6 MB/s eta 0:00:03',\n '   ------------------------ --------------- 26.7/44.0 MB 8.7 MB/s eta 0:00:02',\n '   ------------------------ --------------- 27.1/44.0 MB 8.7 MB/s eta 0:00:02',\n '   ------------------------- -------------- 27.6/44.0 MB 8.8 MB/s eta 0:00:02',\n '   ------------------------- -------------- 28.0/44.0 MB 8.6 MB/s eta 0:00:02',\n '   ------------------------- -------------- 28.4/44.0 MB 8.7 MB/s eta 0:00:02',\n '   -------------------------- ------------- 28.7/44.0 MB 8.7 MB/s eta 0:00:02',\n '   -------------------------- ------------- 29.2/44.0 MB 8.7 MB/s eta 0:00:02',\n '   -------------------------- ------------- 29.5/44.0 MB 8.6 MB/s eta 0:00:02',\n '   --------------------------- ------------ 29.8/44.0 MB 8.5 MB/s eta 0:00:02',\n '   --------------------------- ------------ 30.3/44.0 MB 8.6 MB/s eta 0:00:02',\n '   --------------------------- ------------ 30.6/44.0 MB 8.5 MB/s eta 0:00:02',\n '   ---------------------------- ----------- 31.0/44.0 MB 8.5 MB/s eta 0:00:02',\n '   ---------------------------- ----------- 31.3/44.0 MB 8.5 MB/s eta 0:00:02',\n '   ---------------------------- ----------- 31.6/44.0 MB 8.4 MB/s eta 0:00:02',\n '   ----------------------------- ---------- 31.9/44.0 MB 8.3 MB/s eta 0:00:02',\n '   ----------------------------- ---------- 31.9/44.0 MB 8.3 MB/s eta 0:00:02',\n '   ----------------------------- ---------- 32.1/44.0 MB 7.9 MB/s eta 0:00:02',\n '   ----------------------------- ---------- 32.6/44.0 MB 7.9 MB/s eta 0:00:02',\n '   ------------------------------ --------- 33.0/44.0 MB 7.9 MB/s eta 0:00:02',\n '   ------------------------------ --------- 33.3/44.0 MB 7.8 MB/s eta 0:00:02',\n '   ------------------------------ --------- 33.7/44.0 MB 7.8 MB/s eta 0:00:02',\n '   ------------------------------- -------- 34.2/44.0 MB 8.0 MB/s eta 0:00:02',\n '   ------------------------------- -------- 34.6/44.0 MB 8.0 MB/s eta 0:00:02',\n '   ------------------------------- -------- 35.1/44.0 MB 7.9 MB/s eta 0:00:02',\n '   -------------------------------- ------- 35.5/44.0 MB 7.9 MB/s eta 0:00:02',\n '   -------------------------------- ------- 35.9/44.0 MB 8.0 MB/s eta 0:00:02',\n '   --------------------------------- ------ 36.4/44.0 MB 8.0 MB/s eta 0:00:01',\n '   --------------------------------- ------ 36.7/44.0 MB 7.9 MB/s eta 0:00:01',\n '   --------------------------------- ------ 37.1/44.0 MB 7.9 MB/s eta 0:00:01',\n '   ---------------------------------- ----- 37.6/44.0 MB 7.9 MB/s eta 0:00:01',\n '   ---------------------------------- ----- 38.1/44.0 MB 8.0 MB/s eta 0:00:01',\n '   ---------------------------------- ----- 38.5/44.0 MB 8.0 MB/s eta 0:00:01',\n '   ----------------------------------- ---- 38.9/44.0 MB 8.0 MB/s eta 0:00:01',\n '   ----------------------------------- ---- 39.3/44.0 MB 8.0 MB/s eta 0:00:01',\n '   ------------------------------------ --- 39.7/44.0 MB 8.1 MB/s eta 0:00:01',\n '   ------------------------------------ --- 40.2/44.0 MB 8.2 MB/s eta 0:00:01',\n '   ------------------------------------ --- 40.6/44.0 MB 8.1 MB/s eta 0:00:01',\n '   ------------------------------------- -- 41.1/44.0 MB 8.2 MB/s eta 0:00:01',\n '   ------------------------------------- -- 41.5/44.0 MB 8.4 MB/s eta 0:00:01',\n '   -------------------------------------- - 41.9/44.0 MB 8.5 MB/s eta 0:00:01',\n '   -------------------------------------- - 42.3/44.0 MB 9.1 MB/s eta 0:00:01',\n '   -------------------------------------- - 42.8/44.0 MB 9.1 MB/s eta 0:00:01',\n '   ---------------------------------------  43.2/44.0 MB 9.1 MB/s eta 0:00:01',\n '   ---------------------------------------  43.6/44.0 MB 9.1 MB/s eta 0:00:01',\n '   ---------------------------------------  44.0/44.0 MB 9.2 MB/s eta 0:00:01',\n '   ---------------------------------------  44.0/44.0 MB 9.2 MB/s eta 0:00:01',\n '   ---------------------------------------  44.0/44.0 MB 9.2 MB/s eta 0:00:01',\n '   ---------------------------------------- 44.0/44.0 MB 8.3 MB/s eta 0:00:00',\n 'Downloading joblib-1.3.2-py3-none-any.whl (302 kB)',\n '   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--',\n '   ---------------------------------------- 302.2/302.2 kB 9.4 MB/s eta 0:00:00',\n 'Using cached Pillow-10.0.0-cp311-cp311-win_amd64.whl (2.5 MB)',\n 'Using cached regex-2023.8.8-cp311-cp311-win_amd64.whl (268 kB)',\n 'Downloading safetensors-0.3.3-cp311-cp311-win_amd64.whl (266 kB)',\n '   ---------------------------------------- 0.0/266.1 kB ? eta -:--:--',\n '   ---------------------------------------- 266.1/266.1 kB 5.4 MB/s eta 0:00:00',\n 'Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)',\n 'Downloading filelock-3.12.3-py3-none-any.whl (11 kB)',\n 'Downloading fsspec-2023.9.0-py3-none-any.whl (173 kB)',\n '   ---------------------------------------- 0.0/173.2 kB ? eta -:--:--',\n '   ---------------------------------------- 173.2/173.2 kB 5.3 MB/s eta 0:00:00',\n 'Building wheels for collected packages: sentence-transformers',\n '  Building wheel for sentence-transformers (setup.py): started',\n \"  Building wheel for sentence-transformers (setup.py): finished with status 'done'\",\n '  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125953 sha256=8d0a56ff6a9f090b10894be1dae1b583730ac190fcbd079713aa0db5158810aa',\n '  Stored in directory: c:\\\\users\\\\qyzyr\\\\appdata\\\\local\\\\pip\\\\cache\\\\wheels\\\\ff\\\\27\\\\bf\\\\ffba8b318b02d7f691a57084ee154e26ed24d012b0c7805881',\n 'Successfully built sentence-transformers',\n 'Installing collected packages: tokenizers, sentencepiece, safetensors, mpmath, threadpoolctl, sympy, scipy, regex, pillow, networkx, joblib, fsspec, filelock, torch, scikit-learn, nltk, huggingface-hub, transformers, torchvision, sentence-transformers',\n 'Successfully installed filelock-3.12.3 fsspec-2023.9.0 huggingface-hub-0.16.4 joblib-1.3.2 mpmath-1.3.0 networkx-3.1 nltk-3.8.1 pillow-10.0.0 regex-2023.8.8 safetensors-0.3.3 scikit-learn-1.3.0 scipy-1.11.2 sentence-transformers-2.2.2 sentencepiece-0.1.99 sympy-1.12 threadpoolctl-3.2.0 tokenizers-0.13.3 torch-2.0.1 torchvision-0.15.2 transformers-4.33.0']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!pip install sentence-transformers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T10:15:11.530568200Z",
     "start_time": "2023-09-05T10:12:23.182987200Z"
    }
   },
   "id": "23ea8118a5ad03eb"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T10:23:53.283448100Z",
     "start_time": "2023-09-12T10:23:47.499090Z"
    }
   },
   "id": "283f3d141d5a101"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Compute sentence embeddings for all sentences\n",
    "sentences = [candidate.sentence for candidate in candidate_phrases]\n",
    "sentence_embeddings = {sentence: model.encode(sentence, convert_to_tensor=True) for sentence in sentences}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-06T09:53:43.557629700Z",
     "start_time": "2023-09-06T09:53:28.308478800Z"
    }
   },
   "id": "79b94c9227405d53"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T10:37:38.981464100Z",
     "start_time": "2023-09-12T10:37:38.968433400Z"
    }
   },
   "id": "8cc05c9b717b9841"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Score: 0.7832\n"
     ]
    }
   ],
   "source": [
    "def dist(wi, wj):\n",
    "    return util.pytorch_cos_sim(\n",
    "        model.encode(wi, convert_to_tensor=True),\n",
    "        model.encode(wj, convert_to_tensor=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_topic_score(multiword_expression, sentence):\n",
    "    \"\"\"\n",
    "    Calculate the topic score between a multiword expression and a sentence.\n",
    "\n",
    "    Args:\n",
    "        multiword_expression (str): The multiword expression.\n",
    "        sentence (str): The sentence containing the expression.\n",
    "\n",
    "    Returns:\n",
    "        float: The topic score (cosine similarity) between the two embeddings.\n",
    "    \"\"\"\n",
    "    # Load the distilbert-base-nli-mean-tokens model\n",
    "\n",
    "    # Encode the multiword expression and sentence into embeddings\n",
    "    expression_embedding = model.encode(multiword_expression, convert_to_tensor=True)\n",
    "    sentence_embedding = model.encode(sentence, convert_to_tensor=True)\n",
    "\n",
    "    # Calculate cosine similarity between the two embeddings\n",
    "    similarity_score = util.pytorch_cos_sim(expression_embedding, sentence_embedding)\n",
    "\n",
    "    # Extract the cosine similarity value from the tensor\n",
    "    topic_score = similarity_score[0].item()\n",
    "\n",
    "    return topic_score\n",
    "\n",
    "def calculate_specificity_score(mw:str, w:List[str])->float:\n",
    "    \"\"\"\n",
    "    Calculate the specificity score (SP) between a multiword expression (mw) and a list of words/multiword expressions (w).\n",
    "\n",
    "    Args:\n",
    "        mw (str): The multiword expression.\n",
    "        w (list of str): The list of words/multiword expressions in the context.\n",
    "\n",
    "    Returns:\n",
    "        float: The specificity score (SP).\n",
    "    \"\"\"\n",
    "    # Load the distilbert-base-nli-mean-tokens model\n",
    "    # Calculate distances between mw and each word/phrase in w\n",
    "    distances = [dist(mw, word) for word in w]\n",
    "\n",
    "    # Calculate the mean of the distances\n",
    "    specificity_score = sum(distances) / len(w)\n",
    "\n",
    "    return specificity_score\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T10:23:55.943726100Z",
     "start_time": "2023-09-12T10:23:55.806335500Z"
    }
   },
   "id": "c831b0c22398fbbf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def is_lemma_in_multiword_expression(noun, multiword_expressions):\n",
    "    # Load the English language model from spaCy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # Process the noun to extract its lemma\n",
    "    noun_doc = nlp(noun)\n",
    "    noun_lemma = noun_doc.lemma\n",
    "\n",
    "    # Check if the lemma of the noun matches the last noun in any of the multiword expressions\n",
    "    for expression in multiword_expressions:\n",
    "        expression_doc = nlp(expression)\n",
    "        last_noun = expression_doc[-1].lemma\n",
    "        \n",
    "        if last_noun and noun_lemma == last_noun:\n",
    "            return True\n",
    "    \n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d66b59c221b51da"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beautiful little cats\n",
      "cat\n",
      "cats\n",
      "5439657043933447811\n",
      "5439657043933447811\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T10:40:28.035275900Z",
     "start_time": "2023-09-13T10:40:27.694350600Z"
    }
   },
   "id": "9c1b6598f51a24b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dda8cf7d0991425f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
