{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "codelab link: https://colab.research.google.com/github/abzzall/unsupervised_annotator1/blob/main/main.ipynb\n",
    "github link: https://github.com/abzzall/unsupervised_annotator1.git"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46554966da38c2ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Extract multiword expression candidates. \n",
    "\t1. Using the part-of-speech tags we extract multiword expression candidates, consisting of sequences of zero or more adjectives (ADJ followed by nouns (NOUN) or proper nouns (PROPNs) sequences.\n",
    "\t2. To generate training data for sequence tagging use sentence encoder like \n",
    "\t\ta. EmbedRank (Bennani- Smires et al., 2018\n",
    "\t\tb. Key2Vec (Mahata et al., 2018)\n",
    "    3. We implemented our Unsupervised Annotator using the POS tagger of SpaCy (Honnibal et al., 2020)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa6f429b03250b9"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "['Requirement already satisfied: spacy in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (3.6.1)',\n 'Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (3.0.12)',\n 'Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (1.0.4)',\n 'Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (1.0.9)',\n 'Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (2.0.7)',\n 'Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (3.0.8)',\n 'Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (8.1.12)',\n 'Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (1.1.2)',\n 'Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (2.4.7)',\n 'Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (2.0.9)',\n 'Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (0.9.0)',\n 'Requirement already satisfied: pathy>=0.10.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (0.10.2)',\n 'Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (6.3.0)',\n 'Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (4.66.1)',\n 'Requirement already satisfied: numpy>=1.15.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (1.25.2)',\n 'Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (2.31.0)',\n 'Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (2.3.0)',\n 'Requirement already satisfied: jinja2 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (3.1.2)',\n 'Requirement already satisfied: setuptools in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (68.0.0)',\n 'Requirement already satisfied: packaging>=20.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (23.1)',\n 'Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from spacy) (3.3.0)',\n 'Requirement already satisfied: annotated-types>=0.4.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.5.0)',\n 'Requirement already satisfied: pydantic-core==2.6.3 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.6.3)',\n 'Requirement already satisfied: typing-extensions>=4.6.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)',\n 'Requirement already satisfied: charset-normalizer<4,>=2 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)',\n 'Requirement already satisfied: idna<4,>=2.5 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)',\n 'Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)',\n 'Requirement already satisfied: certifi>=2017.4.17 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)',\n 'Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)',\n 'Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.1)',\n 'Requirement already satisfied: colorama in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)',\n 'Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)',\n 'Requirement already satisfied: MarkupSafe>=2.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from jinja2->spacy) (2.1.3)']"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "!! pip install spacy "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T11:29:43.268761900Z",
     "start_time": "2023-09-21T11:29:40.867490900Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['Requirement already satisfied: sentence-transformers in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (2.2.2)',\n 'Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from sentence-transformers) (4.33.0)',\n 'Requirement already satisfied: tqdm in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from sentence-transformers) (4.66.1)',\n 'Requirement already satisfied: torch>=1.6.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from sentence-transformers) (2.0.1)',\n 'Requirement already satisfied: torchvision in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from sentence-transformers) (0.15.2)',\n 'Requirement already satisfied: numpy in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from sentence-transformers) (1.25.2)',\n 'Requirement already satisfied: scikit-learn in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from sentence-transformers) (1.3.0)',\n 'Requirement already satisfied: scipy in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from sentence-transformers) (1.11.2)',\n 'Requirement already satisfied: nltk in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from sentence-transformers) (3.8.1)',\n 'Requirement already satisfied: sentencepiece in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from sentence-transformers) (0.1.99)',\n 'Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from sentence-transformers) (0.16.4)',\n 'Requirement already satisfied: filelock in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.3)',\n 'Requirement already satisfied: fsspec in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.9.0)',\n 'Requirement already satisfied: requests in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)',\n 'Requirement already satisfied: pyyaml>=5.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)',\n 'Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)',\n 'Requirement already satisfied: packaging>=20.9 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)',\n 'Requirement already satisfied: sympy in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from torch>=1.6.0->sentence-transformers) (1.12)',\n 'Requirement already satisfied: networkx in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1)',\n 'Requirement already satisfied: jinja2 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)',\n 'Requirement already satisfied: colorama in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from tqdm->sentence-transformers) (0.4.6)',\n 'Requirement already satisfied: regex!=2019.12.17 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)',\n 'Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)',\n 'Requirement already satisfied: safetensors>=0.3.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.3)',\n 'Requirement already satisfied: click in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from nltk->sentence-transformers) (8.1.7)',\n 'Requirement already satisfied: joblib in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from nltk->sentence-transformers) (1.3.2)',\n 'Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from scikit-learn->sentence-transformers) (3.2.0)',\n 'Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from torchvision->sentence-transformers) (10.0.0)',\n 'Requirement already satisfied: MarkupSafe>=2.0 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)',\n 'Requirement already satisfied: charset-normalizer<4,>=2 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)',\n 'Requirement already satisfied: idna<4,>=2.5 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)',\n 'Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)',\n 'Requirement already satisfied: certifi>=2017.4.17 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)',\n 'Requirement already satisfied: mpmath>=0.19 in c:\\\\users\\\\qyzyr\\\\onedrive\\\\documents\\\\project_nlp\\\\unsupervised_annotator1\\\\venv\\\\lib\\\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!! python -m spacy download en_core_web_sm\n",
    "!!pip install sentence-transformers\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T11:30:08.650785600Z",
     "start_time": "2023-09-21T11:29:43.267763600Z"
    }
   },
   "id": "cc3d3003d03d7b9e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_infix_regex\n",
    "# Load the language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from typing import List"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T11:30:27.240949700Z",
     "start_time": "2023-09-21T11:30:08.607269600Z"
    }
   },
   "id": "fb5b4593d7f8076e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "# Define your text\n",
    "with open('abstracts.txt') as file:\n",
    "    text=file.read()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T11:30:27.244949700Z",
     "start_time": "2023-09-21T11:30:27.129626600Z"
    }
   },
   "id": "c77006b00543dedb"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# text = \"I love New York and San Francisco. Los Angeles is another great city.\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T11:30:27.246947500Z",
     "start_time": "2023-09-21T11:30:27.143624200Z"
    }
   },
   "id": "35f06edc031c9adb"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "CandidateMWE = namedtuple('CandidateMWE',['text','head', 'sentence','self_encode', 'sent_encode'])\n",
    "CandidateW=namedtuple('CandidateW',['text','lemma', 'self_encode' ])\n",
    "Term=namedtuple('Term',['text','detected' ])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T11:30:27.247954400Z",
     "start_time": "2023-09-21T11:30:27.159811400Z"
    }
   },
   "id": "75546a0cd3d2318d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n",
      " semantic relatedness\n",
      " neighboring words\n",
      " verb WSD\n",
      " general note\n",
      " unsupervised WSD\n",
      "context aware expectation maximization is not candidate 2 aware -- ADJ, True\n",
      " Unsupervised learning\n",
      " relative visual attributes\n",
      " human annotator\n",
      " relative attributes\n",
      " large datasets\n",
      " relative visual attributes\n",
      " training class\n",
      " mixed integer programming problem\n",
      " efficient algorithm\n",
      " good generalization\n",
      " explicit names\n",
      " human annotated attributes\n",
      " relative attributes\n",
      " Unsupervised Domain Adaptation\n",
      " semantic segmentation\n",
      " domain gap\n",
      "label-rich source data is not candidate 2 rich -- ADJ, True\n",
      " unlabeled target data\n",
      " long way\n",
      " scarce labels\n",
      " UDA model\n",
      " uncertain points\n",
      " inconsistency mask\n",
      " supervised performance\n",
      " ground truth points\n",
      " human annotator\n",
      " performance degradation\n",
      " extensive experimentation\n",
      " new framework\n",
      " adaptive semantic segmentation\n",
      " human labor costs\n",
      " Non - expert annotation services\n",
      " Mechanical Turk\n",
      " categorical annotations\n",
      " training data\n",
      " bad labels\n",
      " Manual identification\n",
      " item response model\n",
      " unsupervised fashion\n",
      " correct underlying labels\n",
      " adversarial conditions\n",
      " considerable improvements\n",
      " standard baselines\n",
      " model parameters\n",
      " Variational Bayes inference\n",
      " annotated control instances\n",
      " Multi - Annotator Competence Estimation\n",
      " work concerns\n",
      " automatic topic segmentation\n",
      " email conversations\n",
      " email threads\n",
      " annotator reliability\n",
      " first such email corpus\n",
      " Latent Dirichlet Allocation\n",
      " lexical information\n",
      " lexical information\n",
      " finer level conversation structure\n",
      " principled way\n",
      " Empirical evaluation\n",
      " better model\n",
      " email thread\n",
      " topical clusters\n",
      " conversation structure\n",
      " semantic segmentation models\n",
      " huge amount\n",
      " pixel wise labeling\n",
      " novel framework\n",
      " domain adaptation\n",
      " semantic segmentation\n",
      "image-level weak labels is not candidate 2 weak -- ADJ, True\n",
      " target domain\n",
      " weak labels\n",
      " model prediction\n",
      " unsupervised domain adaptation\n",
      " human annotator\n",
      " WDA paradigm\n",
      " semantic segmentation\n",
      " weak labels\n",
      " image level target annotations\n",
      "category-wise domain alignment is not candidate 2 wise -- ADJ, True\n",
      " weak labels\n",
      " feature alignment\n",
      " domain adaptation\n",
      " weak label classification module\n",
      " certain categories\n",
      " such training signals\n",
      " considerable improvements\n",
      " new benchmark\n",
      " WDA setting\n",
      " Project page\n",
      " http URL\n",
      " TIS prediction\n",
      " current gene finders\n",
      " translation initiation sites\n",
      " first clustering metagenomic fragments\n",
      " phylogenetic groups\n",
      " unsupervised manner\n",
      " TIS prediction\n",
      " current gene finders\n",
      " C++ source code\n",
      " GNU GPL license\n",
      " low shot tasks\n",
      " low shot learning\n",
      " richer supervision\n",
      " annotator rationales\n",
      " label annotations\n",
      " low shot text classification\n",
      " simple bag\n",
      " BERT model\n",
      " substantial performance gains\n",
      " clear top performer\n",
      " more complex models\n",
      " more training data\n",
      " Current dialogue summarization systems\n",
      " general semantic features\n",
      " open domain toolkits\n",
      " human annotations\n",
      " conversational response generation\n",
      " unsupervised dialogue annotator\n",
      " dialogue background knowledge\n",
      " Experimental results\n",
      " remarkable improvements\n",
      " consistent ground truth data\n",
      " interest points\n",
      " natural images\n",
      " interest points\n",
      " human annotator\n",
      " interest point detectors\n",
      " siamese network\n",
      " novel loss function\n",
      " interest point scores\n",
      " point positions\n",
      " non - maximum suppression\n",
      " most trainable detectors\n",
      " pseudo ground truth points\n",
      " novel loss function\n",
      " network predictions\n",
      " homography estimation\n",
      " HPatch dataset\n",
      " Word Sense Disambiguation\n",
      " toughest problems\n",
      " verb disambiguation\n",
      " high degree\n",
      " deep verb hierarchy\n",
      " low inter annotator agreement\n",
      " verb sense annotation\n",
      " Unsupervised WSD\n",
      " widespread attention\n",
      " raw counts\n",
      " comparable corpora\n",
      " accuracy level\n"
     ]
    }
   ],
   "source": [
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract MWEs (noun phrases) from the text\n",
    "mwe_list = []\n",
    "single_noun_list=[]\n",
    "candidate_list=[]\n",
    "for sent in doc.sents:\n",
    "    sent_encode=model.encode(sent.text)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        is_candidate=False\n",
    "        word_count=0\n",
    "        # mwe_list.append(chunk.text)\n",
    "        if len(chunk.text.split()) > 1:\n",
    "            noun_appeared=False\n",
    "            is_candidate=True\n",
    "            cleared_candidate=''\n",
    "            for word in chunk:\n",
    "                #IGNORING\n",
    "                if word.pos_ in ['PUNCT', 'DET']:\n",
    "                    continue\n",
    "                elif word.pos_ not in ['ADJ', 'PROPN', 'NOUN']:\n",
    "                    is_candidate=False\n",
    "                    # print(f'{chunk.text} is not candidate 1 {word.text} -- {word.pos_}')\n",
    "                    break\n",
    "                elif word.pos_ in ['PROPN', 'NOUN']:\n",
    "                    noun_appeared=True\n",
    "                elif not(not noun_appeared and word.pos_=='ADJ'):\n",
    "                    is_candidate=False\n",
    "                    print(f'{chunk.text} is not candidate 2 {word.text} -- {word.pos_}, {noun_appeared}')\n",
    "                    break\n",
    "                cleared_candidate+=' '+word.text\n",
    "                word_count+=1\n",
    "        if is_candidate and word_count>1:\n",
    "            cleared_candidate.strip()\n",
    "            candidate_list.append(CandidateMWE(cleared_candidate, chunk.root.text, sent.text, model.encode(cleared_candidate), sent_encode))\n",
    "            # print(cleared_candidate)\n",
    "        else:\n",
    "            single_noun_list +=[CandidateW(word.text, word.lemma_, model.encode(word.text)) for word in chunk if word.pos_ in ['NOUN', 'PROPN']]\n",
    "                    \n",
    "mwe_list=candidate_list+single_noun_list\n",
    "# print(mwe_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-21T11:30:27.167717900Z"
    }
   },
   "id": "1e716c1702eba543"
  },
  {
   "cell_type": "raw",
   "source": [
    "2. Filter candidates by specificity or topic score.\n",
    "\t1. Topic score. The topic score captures the similarity, topic-wise, between a candidate and the sentence containing it. It is computed as the cosine similarity between the embedding vector of the multiword expression and the embedding vector of the sentence containing it. \n",
    "\t2. Specificity score (SP). This is the mean of the pairwise distance, in the embedding space, between the multiword expressions and all the other word or multiword expression in the context. Specifically, given a multiword mw, and the word or multiword expression w1; :::;wk in its context, we define the specificity score SP as: \n",
    "\t\n",
    "\t\ta. SP(mw)=sum(dist(wi, mw))/k\n",
    "\t\twhere dist(wi;wj) is the cosine-similarity between the embedding vectors of wi and wj . Multiword expressions with a higher score correspond to more specific terms.\n",
    "\t3. In our implementation we use the pretrained sentence encoders described in Reimers and Gurevych (2019),\n",
    "\t\ta. To compute the specificity and similarity scores we use the sentence embedding model distilbert-base-nli-mean-tokens from the sentence transformers library. pypi.org/project/sentence-transformers/. \n",
    "\t\t1. other sentence encoders can be used as a drop-in replacement.\n",
    "\t4. Multiword expressions with a specificity or topic score below a certain threshold can be filtered out.\n",
    "\t\ta. TSP = 0.05\n",
    "\t\tb. Ttopic = 0.1."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34484dd181b5010f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(candidate_list)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "79902c5a4f750a7d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dist(wi_encode, wj_encode)->float:\n",
    "    return util.pytorch_cos_sim(\n",
    "        wi_encode,\n",
    "        wj_encode\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_topic_score(expression_embedding, sentence_embedding)->float:\n",
    "    \"\"\"\n",
    "    Calculate the topic score between a multiword expression and a sentence.\n",
    "\n",
    "    Args:\n",
    "        multiword_expression (str): The multiword expression.\n",
    "        sentence (str): The sentence containing the expression.\n",
    "\n",
    "    Returns:\n",
    "        float: The topic score (cosine similarity) between the two embeddings.\n",
    "    \"\"\"\n",
    "    # Load the distilbert-base-nli-mean-tokens model\n",
    "\n",
    "    # Encode the multiword expression and sentence into embeddings\n",
    "    # expression_embedding = model.encode(multiword_expression, convert_to_tensor=True)\n",
    "    # sentence_embedding = model.encode(sentence, convert_to_tensor=True)\n",
    "\n",
    "    # Calculate cosine similarity between the two embeddings\n",
    "    similarity_score = util.pytorch_cos_sim(expression_embedding, sentence_embedding)\n",
    "\n",
    "    # Extract the cosine similarity value from the tensor\n",
    "    topic_score = similarity_score[0].item()\n",
    "\n",
    "    return topic_score\n",
    "\n",
    "def calculate_specificity_score(mw:CandidateMWE, w:List[CandidateW|CandidateMWE])->float:\n",
    "    \"\"\"\n",
    "    Calculate the specificity score (SP) between a multiword expression (mw) and a list of words/multiword expressions (w).\n",
    "\n",
    "    Args:\n",
    "        mw (str): The multiword expression.\n",
    "        w (list of str): The list of words/multiword expressions in the context.\n",
    "\n",
    "    Returns:\n",
    "        float: The specificity score (SP).\n",
    "    \"\"\"\n",
    "    # Load the distilbert-base-nli-mean-tokens model\n",
    "    # Calculate distances between mw and each word/phrase in w\n",
    "    distances = [dist(mw.self_encode, wi.self_encode) for wi in w if wi != mw]\n",
    "\n",
    "    # Calculate the mean of the distances\n",
    "    specificity_score = sum(distances) / len(w)\n",
    "\n",
    "    return specificity_score\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6203549fb3899ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TSP = 0.05\n",
    "Ttopic = 0.1"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "257ab1172a63c0f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "candidate_list"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "dfe2ed8de75a9f64"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "term_mws=[]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "aabdd9151f59fd0f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for candidate in candidate_list:\n",
    "    topic_score=calculate_topic_score(candidate.self_encode, candidate.sent_encode)\n",
    "    sp_score=calculate_specificity_score(candidate, mwe_list)\n",
    "    if topic_score>Ttopic and sp_score>TSP:\n",
    "        term_mws.append(Term(candidate.text, 'by_score'))\n",
    "        print(candidate.text, topic_score, sp_score)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a7764eb22a80e680"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Upgrade single nouns according to morphological features.\n",
    "\t1. At this stage, we could have nouns that are not part of any multiword expressions, but still relevant.\n",
    "\t2. Check if the lemma of the noun is the same as any of the heads of the multiword expressions.\n",
    "\t\ta. Yes: we upgrade the noun to term \n",
    "\t\tb. No: segment the word using a subword-unit segmentation and a vocabulary trained over a large general purpose corpus.\n",
    "we use the vocabulary of the BERT-base model from HuggingFace (Wolf et al., 2020) and the corresponding tokenizer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d5e0d6670d5f310"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "8d83d9d8fb91f457"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f9ddd1da71dd8608"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "term_nouns=[]\n",
    "subtoken_threshold=4\n",
    "for candidate in single_noun_list:\n",
    "    #Check if the lemma of the noun is the same as any of the heads of the multiword expressions.\n",
    "    is_term=False\n",
    "    lemma_is_head=False\n",
    "    for term_mw in term_mws:\n",
    "        if term_mw.head==candidate.lemma:\n",
    "            is_term=True\n",
    "            break\n",
    "    if is_term:\n",
    "        term_nouns.append(Term(candidate.text, 'by_lemma'))\n",
    "        continue\n",
    "    #segment the word using a subword-unit segmentation and a vocabulary trained over a large general purpose corpus.\n",
    "    subtokens=tokenizer.tokenize(candidate.text)\n",
    "    if len(subtokens)>subtoken_threshold:\n",
    "        term_nouns.append(Term(candidate.text, 'by_subtokens'))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6d91c0e70d37709"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "terms=term_mws+term_nouns\n",
    "with open('out.txt', 'w') as out_file:\n",
    "    for term in terms:\n",
    "        out_file.write(f'\"{term.text}\" appended {term.detected}\\n')\n",
    "        print(f'\"{term.text}\" appended {term.detected}\\n')\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5ef2038896ab2162"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "16f701bdf06e9728"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2b6623bcdf9b97e4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
